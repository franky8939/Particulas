{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTRENAMIENTO DE TERSONFLOW PARA DATA DE ELECTROCARDIOGRAMAS**\n",
    "\n",
    "#NOTACION A USAR *son las variables q no son pertinentes en el estudio\n",
    "NOTA: Los datos originales poseen una fila que se debe eliminar a mano ya que la misma tiene mas columnas que las otras\n",
    "1. survival -- the number of months patient survived (has survived, if patient is still alive).  \n",
    "2. still-alive -- a binary variable.  0=dead at end of survival period, 1 means still alive \n",
    "3. age-at-heart-attack -- age in years when heart attack occurred\n",
    "4. pericardial-effusion -- binary. Pericardial effusion is fluid around the heart.  0=no fluid, 1=fluid\n",
    "5. fractional-shortening -- a measure of contracility around the heart lower numbers are increasingly abnormal\n",
    "6. epss -- E-point septal separation, another measure of contractility. Larger numbers are increasingly abnormal.\n",
    "7. lvdd -- left ventricular end-diastolic dimension.  This is a measure of the size of the heart at end-diastole. Large hearts tend to be sick hearts.\n",
    "8. wall-motion-score -- a measure of how the segments of the left ventricle are moving\n",
    "9. wall-motion-index -- equals wall-motion-score divided by number of segments seen.  Usually 12-13 segments are seen in an echocardiogram.  Use this variable INSTEAD of the wall motion score.\n",
    "10. mult -- a derivate var which can be ignored\n",
    "11. name -- the name of the patient (I have replaced them with \"name\")\n",
    "12. group -- meaningless, ignore it\n",
    "13. alive-at-1 -- Boolean-valued. Derived from the first two attributes. 0 means patient was either dead after 1 year or had been followed for less than 1 year.  1 means patient was alive at 1 year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PAQUETERIAS NECESARIAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow import keras\n",
    "# Bibliotecas de ayuda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#Biblioteca para datos de entrenamiento\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTRADA DE LA INFORMACION, ORDENAMIENTO DE LA INFORMACION A USAR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTACION DE LAS VARIABLES \n",
    "label_total=[\"survival\", \"still_alive\", \"age-at-heart-attack\",\n",
    "       \"pericardial-effusion\",\"fractional-shortening\", \n",
    "       \"epss\", \"lvdd\",\"wall-motion-score\",\"wall-motion-index\",\n",
    "       \"mult\" , \"group\", \"alive-at-1\"];\n",
    "# ENTRAR LA INFORMACION DESDE UN ARCHIVO INTERNO\n",
    "data = pd.DataFrame(np.genfromtxt('echocardiogram.data', delimiter=','), columns= label_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FILTRADO DE LAS VARIABLES QUE SE UTILIZARAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_user=[\"age-at-heart-attack\", \"pericardial-effusion\",\"fractional-shortening\", \"epss\",\n",
    "            \"lvdd\",\"wall-motion-index\", \"alive-at-1\"]; # ELECCION DE LAS COLUMNAS\n",
    "select_data=data[label_user];#DATOS ORIGINALES SIN FILTRAR, COLUMNAS DE INTERES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONOCER EL OUTPUT**\n",
    "\n",
    "Este se relaciona con la posibilidad (en forma binaria) de encontrar al paciente vivo o muerto al aÃ±o del infarto. El formato es de dos columnas y las opciones permitidas son [1,0],[0,1],[-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(select_data[\"alive-at-1-false\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\.conda\\envs\\ML\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "select_data[\"alive-at-1-false\"]=0;  #CREAR COLUMNA EXTRA\n",
    "for j in range(len(select_data)):   #SELECCION DE CONDICIONES\n",
    "    if   data[label_total[0]].values[j] > 12:   #VIVIO MAS DE 12 MESES\n",
    "         select_data[\"alive-at-1\"].values[j] = 1;       #CUMPLE EL REQUISITO\n",
    "         select_data[\"alive-at-1-false\"].values[j] = 0; \n",
    "    elif data[label_total[0]].values[j] == 12 and data[label_total[1]].values[j] == 1:  #CASO PARTICULAR, 12 MESES Y VIVE\n",
    "         select_data[\"alive-at-1\"].values[j] = 1;       #CUMPLE EL REQUISITO\n",
    "         select_data[\"alive-at-1-false\"].values[j] = 0; \n",
    "    elif data[label_total[0]].values[j] < 12 and data[label_total[1]].values[j] == 1:  #MENOS DE 12 MESES Y VIVE\n",
    "         select_data[\"alive-at-1\"].values[j] = -1;      #NO CUMPLE EL REQUISITO\n",
    "         select_data[\"alive-at-1-false\"].values[j] = -1;    \n",
    "    else:   # EL RESTO DE LOS DATOS\n",
    "         select_data[\"alive-at-1\"].values[j] = 0;       #CUMPLE EL REQUISITO DE ESTAR MUERTO\n",
    "         select_data[\"alive-at-1-false\"].values[j] = 1;\n",
    "#    if  random.random()>.5:\n",
    "#        select_data[\"alive-at-1\"].values[j] = 0; #ruido\n",
    "#        select_data[\"alive-at-1-false\"].values[j] = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select_data[\"alive-at-1-\"]=-1\n",
    "#print(select_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MATRIX LOGICA DE DATOS ELIMINAR LAS FILAS CON -1 (DESCONOCIDO)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(label_user)):\n",
    "    if i==0:\n",
    "        log=select_data[label_user[i]] !=-1;#print(i);\n",
    "    else:\n",
    "        log= np.logical_and(select_data[label_user[i]] !=-1,log)\n",
    "select_data=select_data[log]; # filtrar los desconocidos           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEFINICION DE MIS VALORES INPUT Y OUTPUT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data, input_data_test, output_data, output_data_test = train_test_split(\n",
    "    select_data[{\"age-at-heart-attack\", \"pericardial-effusion\",\"fractional-shortening\", \n",
    "                 \"epss\", \"lvdd\",\"wall-motion-index\"}], \n",
    "    select_data[{\"alive-at-1\",\"alive-at-1-false\"}], test_size=0.2, shuffle = True);\n",
    "    #select_data[{\"alive-at-1\"}], test_size=0.2, shuffle = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARAMETROS INICIALES DE ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = np.int64(len(label_user)-1)   # input layer\n",
    "n_hidden = np.int64(np.round(np.sqrt(len(label_user)))) # 1st hidden layer\n",
    "n_output = np.int64(2)   # output \n",
    "\n",
    "learning_rate = 1e-4;   n_iterations = 100   ;   batch_size = 3;         dropout = 0.5\n",
    "\n",
    "X = tf.compat.v1.placeholder(\"float\", [None, n_input]); Y = tf.compat.v1.placeholder(\"float\", [None, n_output])\n",
    "\n",
    "weights = {'w1': tf.Variable(tf.random.normal([n_input, n_hidden])),\n",
    "    'out': tf.Variable(tf.random.normal([n_hidden, n_output]))}\n",
    "\n",
    "biases = {'b1': tf.Variable(tf.constant(0.1, shape=[n_hidden])),\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[n_output]))}\n",
    "\n",
    "layer_1 = tf.add(tf.matmul(X, weights['w1']), biases['b1'])\n",
    "output_layer = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=output_layer))\n",
    "train_step = tf.compat.v1.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(output_layer, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INICIALIZAR EL ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "cost_summary = tf.compat.v1.summary.scalar(\"Cost\", cross_entropy)\n",
    "acc_summary = tf.compat.v1.summary.scalar(\"Accuracy\", accuracy)\n",
    "all_summary = tf.compat.v1.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000e+00 4.3000e-01 4.7900e+00 5.4000e+01 9.3000e+00 0.0000e+00]\n",
      " [1.0000e+00 3.6000e-01 5.7800e+00 6.5000e+01 8.8000e+00 0.0000e+00]\n",
      " [1.0000e+00 2.6000e-01 4.6000e+00 7.1000e+01 9.0000e+00 0.0000e+00]\n",
      " [1.8750e+00 2.3000e-01 5.4300e+00 6.2000e+01 3.1000e+01 0.0000e+00]\n",
      " [1.0000e+00 2.6000e-01 4.3100e+00 6.8000e+01 5.0000e+00 0.0000e+00]\n",
      " [2.2500e+00 1.6000e-01 5.7500e+00 5.7000e+01 2.2000e+01 0.0000e+00]\n",
      " [1.3000e+00 1.5000e-01 4.2700e+00 7.9000e+01 1.7500e+01 0.0000e+00]\n",
      " [1.0000e+00 2.6000e-01 3.4200e+00 5.5000e+01 4.0000e+00 0.0000e+00]\n",
      " [1.0000e+00 1.5000e-01 3.6600e+00 4.8000e+01 1.2000e+01 0.0000e+00]\n",
      " [1.0000e+00 3.0000e-01 3.4900e+00 5.8000e+01 9.4000e+00 0.0000e+00]\n",
      " [1.1900e+00 1.4000e-01 4.4900e+00 5.4000e+01 1.3000e+01 0.0000e+00]\n",
      " [1.3100e+00 3.0000e-02 6.2900e+00 5.9000e+01 2.1300e+01 0.0000e+00]\n",
      " [1.0000e+00 3.4400e-01 4.0400e+00 5.9000e+01 9.1000e+00 0.0000e+00]\n",
      " [1.2220e+00 3.5000e-01 3.6300e+00 5.4000e+01 9.3000e+00 0.0000e+00]\n",
      " [1.1400e+00 3.4000e-01 5.0900e+00 4.6000e+01 0.0000e+00 0.0000e+00]\n",
      " [1.0000e+00 2.9000e-01 6.1500e+00 6.6000e+01 1.5600e+01 0.0000e+00]\n",
      " [1.0900e+00 6.0000e-02 6.7400e+00 6.5000e+01 2.3600e+01 0.0000e+00]\n",
      " [1.0000e+00 2.9000e-01 4.7700e+00 5.7000e+01 9.4000e+00 0.0000e+00]\n",
      " [1.1000e+00 2.8000e-01 5.4700e+00 6.4000e+01 5.4000e+00 0.0000e+00]\n",
      " [1.0000e+00 4.1000e-01 4.3600e+00 8.0000e+01 5.4000e+00 0.0000e+00]\n",
      " [1.6700e+00 1.2000e-01 4.3100e+00 6.0000e+01 1.0200e+01 0.0000e+00]\n",
      " [1.0000e+00 2.5000e-01 4.7200e+00 5.6000e+01 1.1000e+01 0.0000e+00]\n",
      " [1.7300e+00 1.9000e-01 5.0400e+00 6.1000e+01 1.3200e+01 1.0000e+00]\n",
      " [2.3000e+00 1.0000e-01 5.3000e+00 7.0000e+01 9.8000e+00 0.0000e+00]\n",
      " [1.0000e+00 2.2800e-01 4.2900e+00 5.7000e+01 9.7000e+00 0.0000e+00]\n",
      " [1.0800e+00 1.5000e-01 4.5700e+00 6.3000e+01 1.3000e+01 0.0000e+00]\n",
      " [1.3700e+00 1.3000e-01 4.3700e+00 5.7000e+01 1.8600e+01 0.0000e+00]\n",
      " [1.0000e+00 2.5000e-01 4.4800e+00 6.2000e+01 6.0000e+00 0.0000e+00]\n",
      " [1.9500e+00 1.9000e-01 6.6300e+00 6.2000e+01 2.8900e+01 1.0000e+00]\n",
      " [1.5000e+00 7.0000e-02 4.1600e+00 5.4000e+01 1.6800e+01 1.0000e+00]\n",
      " [1.5000e+00 5.0000e-01 3.4200e+00 5.9000e+01 9.1000e+00 0.0000e+00]\n",
      " [1.0000e+00 1.6000e-01 5.2600e+00 5.1000e+01 1.3200e+01 0.0000e+00]\n",
      " [1.8300e+00 2.8000e-01 4.4800e+00 5.5000e+01 5.5000e+00 0.0000e+00]\n",
      " [1.1400e+00 4.5000e-01 3.6000e+00 6.2000e+01 9.0000e+00 1.0000e+00]\n",
      " [1.5000e+00 1.7000e-01 5.4900e+00 5.9000e+01 1.4300e+01 0.0000e+00]\n",
      " [1.0500e+00 1.7000e-01 5.1500e+00 7.9000e+01 1.1900e+01 0.0000e+00]\n",
      " [1.2700e+00 3.0000e-01 4.3600e+00 6.4000e+01 6.6000e+00 0.0000e+00]\n",
      " [1.0000e+00 2.5000e-01 4.2900e+00 5.5000e+01 1.2063e+01 1.0000e+00]\n",
      " [1.1100e+00 1.9000e-01 3.4800e+00 6.4000e+01 5.9000e+00 0.0000e+00]\n",
      " [1.0000e+00 1.6000e-01 5.2500e+00 7.0000e+01 1.9200e+01 1.0000e+00]\n",
      " [2.0000e+00 2.7000e-01 4.4900e+00 7.0000e+01 4.7000e+00 1.0000e+00]\n",
      " [1.1000e+00 2.5000e-01 5.5700e+00 7.0000e+01 9.7000e+00 1.0000e+00]\n",
      " [1.2700e+00 1.5000e-01 4.1700e+00 6.4000e+01 6.6000e+00 0.0000e+00]\n",
      " [1.0800e+00 2.9000e-01 4.7500e+00 5.9000e+01 7.5000e+00 0.0000e+00]\n",
      " [1.2100e+00 2.0000e-01 5.0500e+00 6.9000e+01 7.0000e+00 0.0000e+00]\n",
      " [1.4090e+00 1.5000e-01 4.5100e+00 6.2000e+01 0.0000e+00 0.0000e+00]\n",
      " [1.3330e+00 9.0000e-02 5.8190e+00 6.6000e+01 1.7000e+01 0.0000e+00]\n",
      " [1.1800e+00 2.1700e-01 4.5400e+00 5.4000e+01 1.7900e+01 0.0000e+00]\n",
      " [1.3800e+00 2.4000e-01 5.2600e+00 5.7000e+01 1.4800e+01 0.0000e+00]\n",
      " [1.0000e+00 2.0000e-01 5.2000e+00 6.3000e+01 5.0000e+00 0.0000e+00]\n",
      " [1.0000e+00 2.2000e-01 3.9200e+00 6.2000e+01 1.2100e+01 0.0000e+00]\n",
      " [1.0000e+00 3.3000e-01 4.0000e+00 7.3000e+01 6.0000e+00 0.0000e+00]\n",
      " [1.0000e+00 4.0000e-01 5.3600e+00 5.9000e+01 9.2000e+00 1.0000e+00]\n",
      " [1.0000e+00 2.7000e-01 4.0600e+00 6.1000e+01 9.0000e+00 0.0000e+00]\n",
      " [1.7000e+00 3.8000e-01 4.1000e+00 7.2000e+01 6.0000e+00 0.0000e+00]\n",
      " [1.1500e+00 1.4000e-01 6.2100e+00 5.2000e+01 2.5000e+01 0.0000e+00]\n",
      " [2.2000e+00 2.4000e-01 4.3800e+00 6.6000e+01 1.3600e+01 0.0000e+00]\n",
      " [1.0000e+00 4.0000e-01 3.1000e+00 4.7000e+01 5.1200e+00 0.0000e+00]\n",
      " [1.4500e+00 2.5300e-01 4.6030e+00 6.0000e+01 1.2062e+01 0.0000e+00]\n",
      " [1.0400e+00 1.8000e-01 4.5600e+00 6.0000e+01 8.7000e+00 0.0000e+00]\n",
      " [1.0000e+00 1.5000e-01 3.7300e+00 6.0000e+01 1.0000e+01 0.0000e+00]\n",
      " [1.9500e+00 2.4000e-01 5.8600e+00 6.2000e+01 2.8600e+01 1.0000e+00]\n",
      " [1.0000e+00 2.5800e-01 4.8700e+00 6.2000e+01 1.1800e+01 0.0000e+00]\n",
      " [2.3900e+00 6.0000e-02 5.9500e+00 5.0000e+01 3.0100e+01 0.0000e+00]\n",
      " [1.5600e+00 2.1000e-01 4.1600e+00 5.5000e+01 4.2000e+00 1.0000e+00]] [[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(input_data.values,output_data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 \t| Loss = 2.3083694 \t| Accuracy = 0.9230769\n",
      "Iteration 1 \t| Loss = 2.3051987 \t| Accuracy = 0.9230769\n",
      "Iteration 2 \t| Loss = 2.3020282 \t| Accuracy = 0.9230769\n",
      "Iteration 3 \t| Loss = 2.2988582 \t| Accuracy = 0.9230769\n",
      "Iteration 4 \t| Loss = 2.2956884 \t| Accuracy = 0.9230769\n",
      "Iteration 5 \t| Loss = 2.2925186 \t| Accuracy = 0.9230769\n",
      "Iteration 6 \t| Loss = 2.2893493 \t| Accuracy = 0.9230769\n",
      "Iteration 7 \t| Loss = 2.2861803 \t| Accuracy = 0.9230769\n",
      "Iteration 8 \t| Loss = 2.2830114 \t| Accuracy = 0.9230769\n",
      "Iteration 9 \t| Loss = 2.2798429 \t| Accuracy = 0.9230769\n",
      "Iteration 10 \t| Loss = 2.2766743 \t| Accuracy = 0.9230769\n",
      "Iteration 11 \t| Loss = 2.2735069 \t| Accuracy = 0.9230769\n",
      "Iteration 12 \t| Loss = 2.2703393 \t| Accuracy = 0.9230769\n",
      "Iteration 13 \t| Loss = 2.267172 \t| Accuracy = 0.9230769\n",
      "Iteration 14 \t| Loss = 2.264005 \t| Accuracy = 0.9230769\n",
      "Iteration 15 \t| Loss = 2.2608385 \t| Accuracy = 0.9230769\n",
      "Iteration 16 \t| Loss = 2.2576723 \t| Accuracy = 0.9230769\n",
      "Iteration 17 \t| Loss = 2.254506 \t| Accuracy = 0.9230769\n",
      "Iteration 18 \t| Loss = 2.2513404 \t| Accuracy = 0.9230769\n",
      "Iteration 19 \t| Loss = 2.2481747 \t| Accuracy = 0.9230769\n",
      "Iteration 20 \t| Loss = 2.24501 \t| Accuracy = 0.9230769\n",
      "Iteration 21 \t| Loss = 2.2418451 \t| Accuracy = 0.9230769\n",
      "Iteration 22 \t| Loss = 2.2386806 \t| Accuracy = 0.9230769\n",
      "Iteration 23 \t| Loss = 2.2355168 \t| Accuracy = 0.9230769\n",
      "Iteration 24 \t| Loss = 2.2323532 \t| Accuracy = 0.9230769\n",
      "Iteration 25 \t| Loss = 2.2291903 \t| Accuracy = 0.9230769\n",
      "Iteration 26 \t| Loss = 2.2260275 \t| Accuracy = 0.9230769\n",
      "Iteration 27 \t| Loss = 2.2228649 \t| Accuracy = 0.9230769\n",
      "Iteration 28 \t| Loss = 2.2197027 \t| Accuracy = 0.9230769\n",
      "Iteration 29 \t| Loss = 2.2165403 \t| Accuracy = 0.9230769\n",
      "Iteration 30 \t| Loss = 2.213379 \t| Accuracy = 0.9230769\n",
      "Iteration 31 \t| Loss = 2.2102177 \t| Accuracy = 0.9230769\n",
      "Iteration 32 \t| Loss = 2.2070565 \t| Accuracy = 0.9230769\n",
      "Iteration 33 \t| Loss = 2.2038958 \t| Accuracy = 0.9230769\n",
      "Iteration 34 \t| Loss = 2.2007353 \t| Accuracy = 0.9230769\n",
      "Iteration 35 \t| Loss = 2.1975756 \t| Accuracy = 0.9230769\n",
      "Iteration 36 \t| Loss = 2.1944156 \t| Accuracy = 0.9230769\n",
      "Iteration 37 \t| Loss = 2.191256 \t| Accuracy = 0.9230769\n",
      "Iteration 38 \t| Loss = 2.188097 \t| Accuracy = 0.9230769\n",
      "Iteration 39 \t| Loss = 2.1849384 \t| Accuracy = 0.9230769\n",
      "Iteration 40 \t| Loss = 2.18178 \t| Accuracy = 0.9230769\n",
      "Iteration 41 \t| Loss = 2.178622 \t| Accuracy = 0.9230769\n",
      "Iteration 42 \t| Loss = 2.175464 \t| Accuracy = 0.9230769\n",
      "Iteration 43 \t| Loss = 2.1723065 \t| Accuracy = 0.9230769\n",
      "Iteration 44 \t| Loss = 2.1691494 \t| Accuracy = 0.9230769\n",
      "Iteration 45 \t| Loss = 2.1659923 \t| Accuracy = 0.9230769\n",
      "Iteration 46 \t| Loss = 2.1628356 \t| Accuracy = 0.9230769\n",
      "Iteration 47 \t| Loss = 2.1596794 \t| Accuracy = 0.9230769\n",
      "Iteration 48 \t| Loss = 2.156523 \t| Accuracy = 0.9230769\n",
      "Iteration 49 \t| Loss = 2.1533675 \t| Accuracy = 0.9230769\n",
      "Iteration 50 \t| Loss = 2.150212 \t| Accuracy = 0.9230769\n",
      "Iteration 51 \t| Loss = 2.1470566 \t| Accuracy = 0.9230769\n",
      "Iteration 52 \t| Loss = 2.143902 \t| Accuracy = 0.9230769\n",
      "Iteration 53 \t| Loss = 2.140748 \t| Accuracy = 0.9230769\n",
      "Iteration 54 \t| Loss = 2.137594 \t| Accuracy = 0.9230769\n",
      "Iteration 55 \t| Loss = 2.1344402 \t| Accuracy = 0.9230769\n",
      "Iteration 56 \t| Loss = 2.1312866 \t| Accuracy = 0.9230769\n",
      "Iteration 57 \t| Loss = 2.1281335 \t| Accuracy = 0.9230769\n",
      "Iteration 58 \t| Loss = 2.1249807 \t| Accuracy = 0.9230769\n",
      "Iteration 59 \t| Loss = 2.121828 \t| Accuracy = 0.9230769\n",
      "Iteration 60 \t| Loss = 2.1186752 \t| Accuracy = 0.9230769\n",
      "Iteration 61 \t| Loss = 2.1155233 \t| Accuracy = 0.9230769\n",
      "Iteration 62 \t| Loss = 2.1123714 \t| Accuracy = 0.9230769\n",
      "Iteration 63 \t| Loss = 2.1092196 \t| Accuracy = 0.9230769\n",
      "Iteration 64 \t| Loss = 2.1060681 \t| Accuracy = 0.9230769\n",
      "Iteration 65 \t| Loss = 2.1029172 \t| Accuracy = 0.9230769\n",
      "Iteration 66 \t| Loss = 2.099766 \t| Accuracy = 0.9230769\n",
      "Iteration 67 \t| Loss = 2.0966153 \t| Accuracy = 0.9230769\n",
      "Iteration 68 \t| Loss = 2.093465 \t| Accuracy = 0.9230769\n",
      "Iteration 69 \t| Loss = 2.0903146 \t| Accuracy = 0.9230769\n",
      "Iteration 70 \t| Loss = 2.0871649 \t| Accuracy = 0.9230769\n",
      "Iteration 71 \t| Loss = 2.084015 \t| Accuracy = 0.9230769\n",
      "Iteration 72 \t| Loss = 2.0808654 \t| Accuracy = 0.9230769\n",
      "Iteration 73 \t| Loss = 2.077716 \t| Accuracy = 0.9230769\n",
      "Iteration 74 \t| Loss = 2.074567 \t| Accuracy = 0.9230769\n",
      "Iteration 75 \t| Loss = 2.0714183 \t| Accuracy = 0.9230769\n",
      "Iteration 76 \t| Loss = 2.0682693 \t| Accuracy = 0.9230769\n",
      "Iteration 77 \t| Loss = 2.065121 \t| Accuracy = 0.9230769\n",
      "Iteration 78 \t| Loss = 2.061973 \t| Accuracy = 0.9230769\n",
      "Iteration 79 \t| Loss = 2.0588253 \t| Accuracy = 0.9230769\n",
      "Iteration 80 \t| Loss = 2.0556774 \t| Accuracy = 0.9230769\n",
      "Iteration 81 \t| Loss = 2.0525298 \t| Accuracy = 0.9230769\n",
      "Iteration 82 \t| Loss = 2.0493827 \t| Accuracy = 0.9230769\n",
      "Iteration 83 \t| Loss = 2.0462356 \t| Accuracy = 0.9230769\n",
      "Iteration 84 \t| Loss = 2.0430884 \t| Accuracy = 0.9230769\n",
      "Iteration 85 \t| Loss = 2.0399415 \t| Accuracy = 0.9230769\n",
      "Iteration 86 \t| Loss = 2.0367954 \t| Accuracy = 0.9230769\n",
      "Iteration 87 \t| Loss = 2.0336487 \t| Accuracy = 0.9230769\n",
      "Iteration 88 \t| Loss = 2.030502 \t| Accuracy = 0.9230769\n",
      "Iteration 89 \t| Loss = 2.027356 \t| Accuracy = 0.9230769\n",
      "Iteration 90 \t| Loss = 2.0242102 \t| Accuracy = 0.9230769\n",
      "Iteration 91 \t| Loss = 2.0210643 \t| Accuracy = 0.9230769\n",
      "Iteration 92 \t| Loss = 2.017918 \t| Accuracy = 0.9230769\n",
      "Iteration 93 \t| Loss = 2.0147724 \t| Accuracy = 0.9230769\n",
      "Iteration 94 \t| Loss = 2.0116267 \t| Accuracy = 0.9230769\n",
      "Iteration 95 \t| Loss = 2.0084813 \t| Accuracy = 0.9230769\n",
      "Iteration 96 \t| Loss = 2.005336 \t| Accuracy = 0.9230769\n",
      "Iteration 97 \t| Loss = 2.0021906 \t| Accuracy = 0.9230769\n",
      "Iteration 98 \t| Loss = 1.9990457 \t| Accuracy = 0.9230769\n",
      "Iteration 99 \t| Loss = 1.9959005 \t| Accuracy = 0.9230769\n",
      "\n",
      "Accuracy on test set: 0.88235295\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "#saver=tf.train.Saver() #SALVAR LA SECCION PARA PODERLA UTILIZAR LUEGO\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"Tensorboard\", sess.graph)\n",
    "    #print(sess)\n",
    "    sess.run(init)\n",
    "    #saver.save(sess, 'modelo')\n",
    "    for i in range(n_iterations):\n",
    "        sess.run(train_step, feed_dict={X: input_data.values, Y: output_data.values})\n",
    "        \n",
    "        summary_results, loss, acc = sess.run([all_summary, cross_entropy, accuracy], feed_dict={X: input_data.values, Y: output_data.values})\n",
    "        writer.add_summary(summary_results, i)\n",
    "        if i%20 == 0:\n",
    "        print(\"Iteration\", str(i), \"\\t| Loss =\", str(loss), \"\\t| Accuracy =\", str(acc))\n",
    "    \n",
    "        if acc==1:\n",
    "            break\n",
    "    test_accuracy = sess.run(accuracy, feed_dict={X: input_data_test.values, Y: output_data_test.values})\n",
    "    print(\"\\nAccuracy on test set:\", test_accuracy)\n",
    "    \n",
    "    a, b = sess.run([tf.argmax(output_layer, 1),tf.argmax(Y,1)], feed_dict={X: input_data.values, Y: output_data.values}) \n",
    "    \n",
    "    for ea, eb in zip(a, b):\n",
    "        print(ea,eb)\n",
    "    #saver.save(sess, 'modelo') #SALVAR EL MODELO EXTERNAMENTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBAR EL MODELO CON LA DATA DE MUESTRA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390\n"
     ]
    }
   ],
   "source": [
    "print(input_data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
