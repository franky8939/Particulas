{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTRENAMIENTO DE TERSONFLOW PARA DATA DE ELECTROCARDIOGRAMAS**\n",
    "\n",
    "#NOTACION A USAR *son las variables q no son pertinentes en el estudio\n",
    "NOTA: Los datos originales poseen una fila que se debe eliminar a mano ya que la misma tiene mas columnas que las otras\n",
    "1. survival -- the number of months patient survived (has survived, if patient is still alive).  \n",
    "2. still-alive -- a binary variable.  0=dead at end of survival period, 1 means still alive \n",
    "3. age-at-heart-attack -- age in years when heart attack occurred\n",
    "4. pericardial-effusion -- binary. Pericardial effusion is fluid around the heart.  0=no fluid, 1=fluid\n",
    "5. fractional-shortening -- a measure of contracility around the heart lower numbers are increasingly abnormal\n",
    "6. epss -- E-point septal separation, another measure of contractility. Larger numbers are increasingly abnormal.\n",
    "7. lvdd -- left ventricular end-diastolic dimension.  This is a measure of the size of the heart at end-diastole. Large hearts tend to be sick hearts.\n",
    "8. wall-motion-score -- a measure of how the segments of the left ventricle are moving\n",
    "9. wall-motion-index -- equals wall-motion-score divided by number of segments seen.  Usually 12-13 segments are seen in an echocardiogram.  Use this variable INSTEAD of the wall motion score.\n",
    "10. mult -- a derivate var which can be ignored\n",
    "11. name -- the name of the patient (I have replaced them with \"name\")\n",
    "12. group -- meaningless, ignore it\n",
    "13. alive-at-1 -- Boolean-valued. Derived from the first two attributes. 0 means patient was either dead after 1 year or had been followed for less than 1 year.  1 means patient was alive at 1 year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PAQUETERIAS A USAR \n",
    "# TensorFlow e tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# Bibliotecas de ayuda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#Biblioteca para datos de entrenamiento\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTRADA DE LA INFORMACION, PROCESAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTACION DE LAS VARIABLES \n",
    "label_total=[\"survival\", \"still_alive\", \"age-at-heart-attack\",\n",
    "       \"pericardial-effusion\",\"fractional-shortening\", \n",
    "       \"epss\", \"lvdd\",\"wall-motion-score\",\"wall-motion-index\",\n",
    "       \"mult\" , \"group\", \"alive-at-1\"];\n",
    "# ENTRAR LA INFORMACION DESDE UN ARCHIVO INTERNO\n",
    "data = pd.DataFrame(np.genfromtxt('echocardiogram.data', delimiter=','), columns= label_total)\n",
    "label_user=[\"age-at-heart-attack\", \"pericardial-effusion\",\"fractional-shortening\", \"epss\",\n",
    "            \"lvdd\",\"wall-motion-index\", \"alive-at-1\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESO DE FILTRADO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\.conda\\envs\\ML\\lib\\site-packages\\pandas\\core\\frame.py:3494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "## FILTRAR LAS VARIABLES QUE SE UTILIZARAN EN EL ENTRENAMIENTO DE ML\n",
    "select_data=data[label_user];#DATOS ORIGINALES SIN FILTRAR, COLUMNAS DE INTERES\n",
    "#ARREGLAR LA COLUMNA DE alive-at-1\"];\n",
    "select_data[[\"alive-at-1-false\"]]=select_data[[\"alive-at-1\"]];\n",
    "#alive= np.zeros(len(select_data));\n",
    "for j in range(len(select_data)):\n",
    "    if   data[label_total[0]][j] > 12:#MAS DE 12 MESES\n",
    "         select_data[\"alive-at-1\"].values[j] = 1; #CUMPLE EL REQUISITO\n",
    "         select_data[\"alive-at-1-false\"].values[j] = 0; #CUMPLE EL REQUISITO CONTRARIO\n",
    "    elif data[label_total[0]][j] == 12 and data[label_total[1]][j] == 1:#12 MESES Y VIVE\n",
    "         select_data[\"alive-at-1\"].values[j] = 1; #CUMPLE EL REQUISITO\n",
    "         select_data[\"alive-at-1-false\"].values[j] = 0; #CUMPLE EL REQUISITO CONTRARIO\n",
    "    elif data[label_total[0]][j] < 12 and data[label_total[1]][j] == 1:# MENOS DE 12 MESES Y VIVE\n",
    "         select_data[\"alive-at-1\"].values[j] = -1; #NO CUMPLE EL REQUISITO\n",
    "         select_data[\"alive-at-1-false\"].values[j] = -1; #CUMPLE EL REQUISITO CONTRARIO   \n",
    "    else:\n",
    "         select_data[\"alive-at-1\"].values[j] = 0; #CUMPLE EL REQUISITO\n",
    "         select_data[\"alive-at-1-false\"].values[j] = 1; #CUMPLE EL REQUISITO CONTRARIO\n",
    "    #from random import random\n",
    "    #if random()>.5:\n",
    "    #    select_data[\"alive-at-1\"].values[j] = 0; #ruido\n",
    "    \n",
    "##MATRIX LOGICA DE DATOS ELIMINAR LO DESCONOCIDO\n",
    "for i in range(len(label_user)):\n",
    "    if i==0:\n",
    "        log=select_data[label_user[i]] !=-1;#print(i);\n",
    "    else:\n",
    "        log= np.logical_and(select_data[label_user[i]] !=-1,log)\n",
    "select_data=select_data[log]; # filtrar los desconocidos           \n",
    "\n",
    "##VALORES FINALES QUE SE UTILIZARAN PARA ENTRENARSE CORRECTAMENTE\n",
    "input_data, input_data_test, output_data, output_data_test = train_test_split(\n",
    "    select_data[{\"age-at-heart-attack\", \"pericardial-effusion\",\"fractional-shortening\", \n",
    "                 \"epss\", \"lvdd\",\"wall-motion-index\"}], \n",
    "    select_data[{\"alive-at-1\",\"alive-at-1-false\"}], test_size=0.2, shuffle = True);\n",
    "\n",
    "#output_data[['alive-at-1-false']]=output_data.values# incluir columna logica al output\n",
    "\n",
    "\n",
    "\n",
    "#input_data=select_data[{\"age-at-heart-attack\", \"pericardial-effusion\",\"fractional-shortening\", \"epss\", \"lvdd\",\"wall-motion-index\"}];\n",
    "#output_data=select_data[{\"alive-at-1\"}];\n",
    "\n",
    "#GRAFICAR ALGUNOS DATOS\n",
    "#print(select_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "#output_data[['alive-at-1-false']]=output_data\n",
    "#print(output_data.values)#np.ones(output_data.size)\n",
    "print(len(output_data.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARAMETROS INICIALES DE ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = np.int64(len(label_user)-1)   # input layer\n",
    "n_hidden = np.int64(np.round(np.sqrt(len(label_user)))) # 1st hidden layer\n",
    "n_output = np.int64(2)   # output \n",
    "\n",
    "learning_rate = 1e-4;   n_iterations = 100\n",
    "batch_size = 3;         dropout = 0.5\n",
    "\n",
    "X = tf.compat.v1.placeholder(\"float\", [None, n_input]);\n",
    "Y = tf.compat.v1.placeholder(\"float\", [None, n_output])\n",
    "#keep_prob = tf.placeholder(tf.float32) \n",
    "\n",
    "weights = {\n",
    "    'w1': tf.Variable(tf.random.normal([n_input, n_hidden])),\n",
    "    'out': tf.Variable(tf.random.normal([n_hidden, n_output]))\n",
    "    }\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.constant(0.1, shape=[n_hidden])),\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[n_output]))\n",
    "}\n",
    "\n",
    "layer_1 = tf.add(tf.matmul(X, weights['w1']), biases['b1'])\n",
    "#layer_drop = tf.nn.dropout(layer_1, keep_prob)\n",
    "output_layer = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=output_layer))\n",
    "train_step = tf.compat.v1.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(output_layer, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INICIALIZAR EL ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "cost_summary = tf.compat.v1.summary.scalar(\"Cost\", cross_entropy)\n",
    "acc_summary = tf.compat.v1.summary.scalar(\"Accuracy\", accuracy)\n",
    "all_summary = tf.compat.v1.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 \t| Loss = 92.597664 \t| Accuracy = 0.092307694\n",
      "Iteration 1 \t| Loss = 92.54187 \t| Accuracy = 0.092307694\n",
      "Iteration 2 \t| Loss = 92.486084 \t| Accuracy = 0.092307694\n",
      "Iteration 3 \t| Loss = 92.43029 \t| Accuracy = 0.092307694\n",
      "Iteration 4 \t| Loss = 92.37452 \t| Accuracy = 0.092307694\n",
      "Iteration 5 \t| Loss = 92.31874 \t| Accuracy = 0.092307694\n",
      "Iteration 6 \t| Loss = 92.262955 \t| Accuracy = 0.092307694\n",
      "Iteration 7 \t| Loss = 92.207184 \t| Accuracy = 0.092307694\n",
      "Iteration 8 \t| Loss = 92.15142 \t| Accuracy = 0.092307694\n",
      "Iteration 9 \t| Loss = 92.09565 \t| Accuracy = 0.092307694\n",
      "Iteration 10 \t| Loss = 92.039894 \t| Accuracy = 0.092307694\n",
      "Iteration 11 \t| Loss = 91.98414 \t| Accuracy = 0.092307694\n",
      "Iteration 12 \t| Loss = 91.92839 \t| Accuracy = 0.092307694\n",
      "Iteration 13 \t| Loss = 91.872635 \t| Accuracy = 0.092307694\n",
      "Iteration 14 \t| Loss = 91.81689 \t| Accuracy = 0.092307694\n",
      "Iteration 15 \t| Loss = 91.76114 \t| Accuracy = 0.092307694\n",
      "Iteration 16 \t| Loss = 91.70539 \t| Accuracy = 0.092307694\n",
      "Iteration 17 \t| Loss = 91.64966 \t| Accuracy = 0.092307694\n",
      "Iteration 18 \t| Loss = 91.59393 \t| Accuracy = 0.092307694\n",
      "Iteration 19 \t| Loss = 91.5382 \t| Accuracy = 0.092307694\n",
      "Iteration 20 \t| Loss = 91.48248 \t| Accuracy = 0.092307694\n",
      "Iteration 21 \t| Loss = 91.426765 \t| Accuracy = 0.092307694\n",
      "Iteration 22 \t| Loss = 91.37105 \t| Accuracy = 0.092307694\n",
      "Iteration 23 \t| Loss = 91.31534 \t| Accuracy = 0.092307694\n",
      "Iteration 24 \t| Loss = 91.259636 \t| Accuracy = 0.092307694\n",
      "Iteration 25 \t| Loss = 91.20392 \t| Accuracy = 0.092307694\n",
      "Iteration 26 \t| Loss = 91.14822 \t| Accuracy = 0.092307694\n",
      "Iteration 27 \t| Loss = 91.09253 \t| Accuracy = 0.092307694\n",
      "Iteration 28 \t| Loss = 91.03686 \t| Accuracy = 0.092307694\n",
      "Iteration 29 \t| Loss = 90.98116 \t| Accuracy = 0.092307694\n",
      "Iteration 30 \t| Loss = 90.925476 \t| Accuracy = 0.092307694\n",
      "Iteration 31 \t| Loss = 90.8698 \t| Accuracy = 0.092307694\n",
      "Iteration 32 \t| Loss = 90.81411 \t| Accuracy = 0.092307694\n",
      "Iteration 33 \t| Loss = 90.75843 \t| Accuracy = 0.092307694\n",
      "Iteration 34 \t| Loss = 90.70277 \t| Accuracy = 0.092307694\n",
      "Iteration 35 \t| Loss = 90.6471 \t| Accuracy = 0.092307694\n",
      "Iteration 36 \t| Loss = 90.59144 \t| Accuracy = 0.092307694\n",
      "Iteration 37 \t| Loss = 90.53577 \t| Accuracy = 0.092307694\n",
      "Iteration 38 \t| Loss = 90.480125 \t| Accuracy = 0.092307694\n",
      "Iteration 39 \t| Loss = 90.42447 \t| Accuracy = 0.092307694\n",
      "Iteration 40 \t| Loss = 90.36882 \t| Accuracy = 0.092307694\n",
      "Iteration 41 \t| Loss = 90.31319 \t| Accuracy = 0.092307694\n",
      "Iteration 42 \t| Loss = 90.25755 \t| Accuracy = 0.092307694\n",
      "Iteration 43 \t| Loss = 90.201904 \t| Accuracy = 0.092307694\n",
      "Iteration 44 \t| Loss = 90.14628 \t| Accuracy = 0.092307694\n",
      "Iteration 45 \t| Loss = 90.090675 \t| Accuracy = 0.092307694\n",
      "Iteration 46 \t| Loss = 90.03504 \t| Accuracy = 0.092307694\n",
      "Iteration 47 \t| Loss = 89.97942 \t| Accuracy = 0.092307694\n",
      "Iteration 48 \t| Loss = 89.92382 \t| Accuracy = 0.092307694\n",
      "Iteration 49 \t| Loss = 89.86821 \t| Accuracy = 0.092307694\n",
      "Iteration 50 \t| Loss = 89.812614 \t| Accuracy = 0.092307694\n",
      "Iteration 51 \t| Loss = 89.75702 \t| Accuracy = 0.092307694\n",
      "Iteration 52 \t| Loss = 89.701416 \t| Accuracy = 0.092307694\n",
      "Iteration 53 \t| Loss = 89.64581 \t| Accuracy = 0.092307694\n",
      "Iteration 54 \t| Loss = 89.59023 \t| Accuracy = 0.092307694\n",
      "Iteration 55 \t| Loss = 89.534645 \t| Accuracy = 0.092307694\n",
      "Iteration 56 \t| Loss = 89.47906 \t| Accuracy = 0.092307694\n",
      "Iteration 57 \t| Loss = 89.42349 \t| Accuracy = 0.092307694\n",
      "Iteration 58 \t| Loss = 89.367905 \t| Accuracy = 0.092307694\n",
      "Iteration 59 \t| Loss = 89.31234 \t| Accuracy = 0.092307694\n",
      "Iteration 60 \t| Loss = 89.25678 \t| Accuracy = 0.092307694\n",
      "Iteration 61 \t| Loss = 89.201225 \t| Accuracy = 0.092307694\n",
      "Iteration 62 \t| Loss = 89.145676 \t| Accuracy = 0.092307694\n",
      "Iteration 63 \t| Loss = 89.09012 \t| Accuracy = 0.092307694\n",
      "Iteration 64 \t| Loss = 89.034584 \t| Accuracy = 0.092307694\n",
      "Iteration 65 \t| Loss = 88.97904 \t| Accuracy = 0.092307694\n",
      "Iteration 66 \t| Loss = 88.923515 \t| Accuracy = 0.092307694\n",
      "Iteration 67 \t| Loss = 88.867966 \t| Accuracy = 0.092307694\n",
      "Iteration 68 \t| Loss = 88.81245 \t| Accuracy = 0.092307694\n",
      "Iteration 69 \t| Loss = 88.756905 \t| Accuracy = 0.092307694\n",
      "Iteration 70 \t| Loss = 88.7014 \t| Accuracy = 0.092307694\n",
      "Iteration 71 \t| Loss = 88.645874 \t| Accuracy = 0.092307694\n",
      "Iteration 72 \t| Loss = 88.590355 \t| Accuracy = 0.092307694\n",
      "Iteration 73 \t| Loss = 88.53485 \t| Accuracy = 0.092307694\n",
      "Iteration 74 \t| Loss = 88.47935 \t| Accuracy = 0.092307694\n",
      "Iteration 75 \t| Loss = 88.423836 \t| Accuracy = 0.092307694\n",
      "Iteration 76 \t| Loss = 88.368355 \t| Accuracy = 0.092307694\n",
      "Iteration 77 \t| Loss = 88.31284 \t| Accuracy = 0.092307694\n",
      "Iteration 78 \t| Loss = 88.25736 \t| Accuracy = 0.092307694\n",
      "Iteration 79 \t| Loss = 88.20188 \t| Accuracy = 0.092307694\n",
      "Iteration 80 \t| Loss = 88.146385 \t| Accuracy = 0.092307694\n",
      "Iteration 81 \t| Loss = 88.09092 \t| Accuracy = 0.092307694\n",
      "Iteration 82 \t| Loss = 88.03544 \t| Accuracy = 0.092307694\n",
      "Iteration 83 \t| Loss = 87.97999 \t| Accuracy = 0.092307694\n",
      "Iteration 84 \t| Loss = 87.92452 \t| Accuracy = 0.092307694\n",
      "Iteration 85 \t| Loss = 87.86906 \t| Accuracy = 0.092307694\n",
      "Iteration 86 \t| Loss = 87.81361 \t| Accuracy = 0.092307694\n",
      "Iteration 87 \t| Loss = 87.75815 \t| Accuracy = 0.092307694\n",
      "Iteration 88 \t| Loss = 87.702705 \t| Accuracy = 0.092307694\n",
      "Iteration 89 \t| Loss = 87.647255 \t| Accuracy = 0.092307694\n",
      "Iteration 90 \t| Loss = 87.591805 \t| Accuracy = 0.092307694\n",
      "Iteration 91 \t| Loss = 87.53638 \t| Accuracy = 0.092307694\n",
      "Iteration 92 \t| Loss = 87.48094 \t| Accuracy = 0.092307694\n",
      "Iteration 93 \t| Loss = 87.425514 \t| Accuracy = 0.092307694\n",
      "Iteration 94 \t| Loss = 87.3701 \t| Accuracy = 0.092307694\n",
      "Iteration 95 \t| Loss = 87.31468 \t| Accuracy = 0.092307694\n",
      "Iteration 96 \t| Loss = 87.25926 \t| Accuracy = 0.092307694\n",
      "Iteration 97 \t| Loss = 87.20385 \t| Accuracy = 0.092307694\n",
      "Iteration 98 \t| Loss = 87.148445 \t| Accuracy = 0.092307694\n",
      "Iteration 99 \t| Loss = 87.09303 \t| Accuracy = 0.092307694\n",
      "\n",
      "Accuracy on test set: 0.05882353\n"
     ]
    }
   ],
   "source": [
    "#saver=tf.train.Saver() #SALVAR LA SECCION PARA PODERLA UTILIZAR LUEGO\n",
    "with tf.Session() as sess:\n",
    "    #writer = tf.summary.FileWriter(\"Tensorboard\", sess.graph)\n",
    "    #print(sess)\n",
    "    sess.run(init)\n",
    "    #saver.save(sess, 'modelo')\n",
    "    for i in range(n_iterations):\n",
    "        sess.run(train_step, feed_dict={X: input_data.values, Y: output_data.values})\n",
    "        #if i % 10 == 0:\n",
    "        summary_results, loss, acc = sess.run([all_summary, cross_entropy, accuracy], feed_dict={X: input_data.values, Y: output_data.values})\n",
    "                #    writer.add_summary(summary_results, i)\n",
    "        print(\"Iteration\", str(i), \"\\t| Loss =\", str(loss), \"\\t| Accuracy =\", str(acc))\n",
    "    \n",
    "        if acc==1:\n",
    "            break\n",
    "    test_accuracy = sess.run(accuracy, feed_dict={X: input_data_test.values, Y: output_data_test.values})\n",
    "    print(\"\\nAccuracy on test set:\", test_accuracy)\n",
    "        \n",
    "    #saver.save(sess, 'modelo') #SALVAR EL MODELO EXTERNAMENTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBAR EL MODELO CON LA DATA DE MUESTRA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2aede903744e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'graph' is not defined"
     ]
    }
   ],
   "source": [
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
