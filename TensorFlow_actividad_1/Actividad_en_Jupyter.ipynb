{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTRENAMIENTO DE TERSONFLOW PARA DATA DE ELECTROCARDIOGRAMAS**\n",
    "\n",
    "#NOTACION A USAR *son las variables q no son pertinentes en el estudio\n",
    "NOTA: Los datos originales poseen una fila que se debe eliminar a mano ya que la misma tiene mas columnas que las otras\n",
    "1. survival -- the number of months patient survived (has survived, if patient is still alive).  \n",
    "2. still-alive -- a binary variable.  0=dead at end of survival period, 1 means still alive \n",
    "3. age-at-heart-attack -- age in years when heart attack occurred\n",
    "4. pericardial-effusion -- binary. Pericardial effusion is fluid around the heart.  0=no fluid, 1=fluid\n",
    "5. fractional-shortening -- a measure of contracility around the heart lower numbers are increasingly abnormal\n",
    "6. epss -- E-point septal separation, another measure of contractility. Larger numbers are increasingly abnormal.\n",
    "7. lvdd -- left ventricular end-diastolic dimension.  This is a measure of the size of the heart at end-diastole. Large hearts tend to be sick hearts.\n",
    "8. wall-motion-score -- a measure of how the segments of the left ventricle are moving\n",
    "9. wall-motion-index -- equals wall-motion-score divided by number of segments seen.  Usually 12-13 segments are seen in an echocardiogram.  Use this variable INSTEAD of the wall motion score.\n",
    "10. mult -- a derivate var which can be ignored\n",
    "11. name -- the name of the patient (I have replaced them with \"name\")\n",
    "12. group -- meaningless, ignore it\n",
    "13. alive-at-1 -- Boolean-valued. Derived from the first two attributes. 0 means patient was either dead after 1 year or had been followed for less than 1 year.  1 means patient was alive at 1 year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PAQUETERIAS A USAR \n",
    "# TensorFlow e tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# Bibliotecas de ayuda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#Biblioteca para datos de entrenamiento\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTRADA DE LA INFORMACION, PROCESAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTACION DE LAS VARIABLES \n",
    "label_total=[\"survival\", \"still_alive\", \"age-at-heart-attack\",\n",
    "       \"pericardial-effusion\",\"fractional-shortening\", \n",
    "       \"epss\", \"lvdd\",\"wall-motion-score\",\"wall-motion-index\",\n",
    "       \"mult\" , \"group\", \"alive-at-1\"];\n",
    "# ENTRAR LA INFORMACION DESDE UN ARCHIVO INTERNO\n",
    "data = pd.DataFrame(np.genfromtxt('echocardiogram.data', delimiter=','), columns= label_total)\n",
    "label_user=[\"age-at-heart-attack\", \"pericardial-effusion\",\"fractional-shortening\", \"epss\",\n",
    "            \"lvdd\",\"wall-motion-index\", \"alive-at-1\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESO DE FILTRADO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\.conda\\envs\\ML\\lib\\site-packages\\pandas\\core\\frame.py:3494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "## FILTRAR LAS VARIABLES QUE SE UTILIZARAN EN EL ENTRENAMIENTO DE ML\n",
    "select_data=data[label_user];#DATOS ORIGINALES SIN FILTRAR, COLUMNAS DE INTERES\n",
    "#ARREGLAR LA COLUMNA DE alive-at-1\"];\n",
    "select_data[[\"alive-at-1-false\"]]=select_data[[\"alive-at-1\"]];\n",
    "#alive= np.zeros(len(select_data));\n",
    "for j in range(len(select_data)):\n",
    "    if   data[label_total[0]][j] > 12:#MAS DE 12 MESES\n",
    "         select_data[\"alive-at-1\"].values[j] = 1; #CUMPLE EL REQUISITO\n",
    "         select_data[\"alive-at-1-false\"].values[j] = 0; #CUMPLE EL REQUISITO CONTRARIO\n",
    "    elif data[label_total[0]][j] == 12 and data[label_total[1]][j] == 1:#12 MESES Y VIVE\n",
    "         select_data[\"alive-at-1\"].values[j] = 1; #CUMPLE EL REQUISITO\n",
    "         select_data[\"alive-at-1-false\"].values[j] = 0; #CUMPLE EL REQUISITO CONTRARIO\n",
    "    elif data[label_total[0]][j] < 12 and data[label_total[1]][j] == 1:# MENOS DE 12 MESES Y VIVE\n",
    "         select_data[\"alive-at-1\"].values[j] = -1; #NO CUMPLE EL REQUISITO\n",
    "         select_data[\"alive-at-1-false\"].values[j] = -1; #CUMPLE EL REQUISITO CONTRARIO   \n",
    "    else:\n",
    "         select_data[\"alive-at-1\"].values[j] = 0; #CUMPLE EL REQUISITO\n",
    "         select_data[\"alive-at-1-false\"].values[j] = 1; #CUMPLE EL REQUISITO CONTRARIO\n",
    "    #from random import random\n",
    "    #if random()>.5:\n",
    "    #    select_data[\"alive-at-1\"].values[j] = 0; #ruido\n",
    "    \n",
    "##MATRIX LOGICA DE DATOS ELIMINAR LO DESCONOCIDO\n",
    "for i in range(len(label_user)):\n",
    "    if i==0:\n",
    "        log=select_data[label_user[i]] !=-1;#print(i);\n",
    "    else:\n",
    "        log= np.logical_and(select_data[label_user[i]] !=-1,log)\n",
    "select_data=select_data[log]; # filtrar los desconocidos           \n",
    "\n",
    "##VALORES FINALES QUE SE UTILIZARAN PARA ENTRENARSE CORRECTAMENTE\n",
    "input_data, input_data_test, output_data, output_data_test = train_test_split(\n",
    "    select_data[{\"age-at-heart-attack\", \"pericardial-effusion\",\"fractional-shortening\", \n",
    "                 \"epss\", \"lvdd\",\"wall-motion-index\"}], \n",
    "    select_data[{\"alive-at-1\",\"alive-at-1-false\"}], test_size=0.2, shuffle = True);\n",
    "\n",
    "#output_data[['alive-at-1-false']]=output_data.values# incluir columna logica al output\n",
    "\n",
    "\n",
    "\n",
    "#input_data=select_data[{\"age-at-heart-attack\", \"pericardial-effusion\",\"fractional-shortening\", \"epss\", \"lvdd\",\"wall-motion-index\"}];\n",
    "#output_data=select_data[{\"alive-at-1\"}];\n",
    "\n",
    "#GRAFICAR ALGUNOS DATOS\n",
    "#print(select_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     epss  lvdd  wall-motion-index  pericardial-effusion  \\\n",
      "2     4.0  3.42               1.00                   0.0   \n",
      "102   0.0  4.55               1.00                   0.0   \n",
      "9    13.0  4.49               1.19                   0.0   \n",
      "55   15.6  6.15               1.00                   0.0   \n",
      "87   19.2  5.25               1.00                   1.0   \n",
      "..    ...   ...                ...                   ...   \n",
      "81   16.8  4.16               1.50                   1.0   \n",
      "115  28.9  6.63               1.95                   1.0   \n",
      "24    5.9  3.48               1.11                   0.0   \n",
      "117   9.3  4.79               1.00                   0.0   \n",
      "57   18.6  4.37               1.37                   0.0   \n",
      "\n",
      "     fractional-shortening  age-at-heart-attack  \n",
      "2                     0.26                 55.0  \n",
      "102                   0.38                 70.0  \n",
      "9                     0.14                 54.0  \n",
      "55                    0.29                 66.0  \n",
      "87                    0.16                 70.0  \n",
      "..                     ...                  ...  \n",
      "81                    0.07                 54.0  \n",
      "115                   0.19                 62.0  \n",
      "24                    0.19                 64.0  \n",
      "117                   0.43                 54.0  \n",
      "57                    0.13                 57.0  \n",
      "\n",
      "[65 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#output_data[['alive-at-1-false']]=output_data\n",
    "#print(output_data.values)#np.ones(output_data.size)\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARAMETROS INICIALES DE ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = np.int64(len(label_user)-1)   # input layer\n",
    "n_hidden = np.int64(np.round(np.sqrt(len(label_user)))) # 1st hidden layer\n",
    "n_output = np.int64(2)   # output \n",
    "\n",
    "learning_rate = 1e-4;   n_iterations = 100\n",
    "batch_size = 3;         dropout = 0.5\n",
    "\n",
    "X = tf.compat.v1.placeholder(\"float\", [None, n_input]);\n",
    "Y = tf.compat.v1.placeholder(\"float\", [None, n_output])\n",
    "#keep_prob = tf.placeholder(tf.float32) \n",
    "\n",
    "weights = {\n",
    "    'w1': tf.Variable(tf.random.normal([n_input, n_hidden])),\n",
    "    'out': tf.Variable(tf.random.normal([n_hidden, n_output]))\n",
    "    }\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.constant(0.1, shape=[n_hidden])),\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[n_output]))\n",
    "}\n",
    "\n",
    "layer_1 = tf.add(tf.matmul(X, weights['w1']), biases['b1'])\n",
    "#layer_drop = tf.nn.dropout(layer_1, keep_prob)\n",
    "output_layer = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=output_layer))\n",
    "train_step = tf.compat.v1.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(output_layer, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INICIALIZAR EL ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "cost_summary = tf.compat.v1.summary.scalar(\"Cost\", cross_entropy)\n",
    "acc_summary = tf.compat.v1.summary.scalar(\"Accuracy\", accuracy)\n",
    "all_summary = tf.compat.v1.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 \t| Loss = 11.20876 \t| Accuracy = 0.9230769\n",
      "Iteration 1 \t| Loss = 11.205221 \t| Accuracy = 0.9230769\n",
      "Iteration 2 \t| Loss = 11.201681 \t| Accuracy = 0.9230769\n",
      "Iteration 3 \t| Loss = 11.198145 \t| Accuracy = 0.9230769\n",
      "Iteration 4 \t| Loss = 11.194607 \t| Accuracy = 0.9230769\n",
      "Iteration 5 \t| Loss = 11.191071 \t| Accuracy = 0.9230769\n",
      "Iteration 6 \t| Loss = 11.187533 \t| Accuracy = 0.9230769\n",
      "Iteration 7 \t| Loss = 11.183999 \t| Accuracy = 0.9230769\n",
      "Iteration 8 \t| Loss = 11.180465 \t| Accuracy = 0.9230769\n",
      "Iteration 9 \t| Loss = 11.176931 \t| Accuracy = 0.9230769\n",
      "Iteration 10 \t| Loss = 11.1734 \t| Accuracy = 0.9230769\n",
      "Iteration 11 \t| Loss = 11.169868 \t| Accuracy = 0.9230769\n",
      "Iteration 12 \t| Loss = 11.166339 \t| Accuracy = 0.9230769\n",
      "Iteration 13 \t| Loss = 11.16281 \t| Accuracy = 0.9230769\n",
      "Iteration 14 \t| Loss = 11.159281 \t| Accuracy = 0.9230769\n",
      "Iteration 15 \t| Loss = 11.155754 \t| Accuracy = 0.9230769\n",
      "Iteration 16 \t| Loss = 11.152229 \t| Accuracy = 0.9230769\n",
      "Iteration 17 \t| Loss = 11.148705 \t| Accuracy = 0.9230769\n",
      "Iteration 18 \t| Loss = 11.14518 \t| Accuracy = 0.9230769\n",
      "Iteration 19 \t| Loss = 11.141657 \t| Accuracy = 0.9230769\n",
      "Iteration 20 \t| Loss = 11.138135 \t| Accuracy = 0.9230769\n",
      "Iteration 21 \t| Loss = 11.134613 \t| Accuracy = 0.9230769\n",
      "Iteration 22 \t| Loss = 11.131094 \t| Accuracy = 0.9230769\n",
      "Iteration 23 \t| Loss = 11.127575 \t| Accuracy = 0.9230769\n",
      "Iteration 24 \t| Loss = 11.124057 \t| Accuracy = 0.9230769\n",
      "Iteration 25 \t| Loss = 11.12054 \t| Accuracy = 0.9230769\n",
      "Iteration 26 \t| Loss = 11.117024 \t| Accuracy = 0.9230769\n",
      "Iteration 27 \t| Loss = 11.113508 \t| Accuracy = 0.9230769\n",
      "Iteration 28 \t| Loss = 11.109995 \t| Accuracy = 0.9230769\n",
      "Iteration 29 \t| Loss = 11.106481 \t| Accuracy = 0.9230769\n",
      "Iteration 30 \t| Loss = 11.102969 \t| Accuracy = 0.9230769\n",
      "Iteration 31 \t| Loss = 11.099459 \t| Accuracy = 0.9230769\n",
      "Iteration 32 \t| Loss = 11.095949 \t| Accuracy = 0.9230769\n",
      "Iteration 33 \t| Loss = 11.092441 \t| Accuracy = 0.9230769\n",
      "Iteration 34 \t| Loss = 11.088932 \t| Accuracy = 0.9230769\n",
      "Iteration 35 \t| Loss = 11.085424 \t| Accuracy = 0.9230769\n",
      "Iteration 36 \t| Loss = 11.081921 \t| Accuracy = 0.9230769\n",
      "Iteration 37 \t| Loss = 11.078416 \t| Accuracy = 0.9230769\n",
      "Iteration 38 \t| Loss = 11.074912 \t| Accuracy = 0.9230769\n",
      "Iteration 39 \t| Loss = 11.071409 \t| Accuracy = 0.9230769\n",
      "Iteration 40 \t| Loss = 11.067906 \t| Accuracy = 0.9230769\n",
      "Iteration 41 \t| Loss = 11.064408 \t| Accuracy = 0.9230769\n",
      "Iteration 42 \t| Loss = 11.060907 \t| Accuracy = 0.9230769\n",
      "Iteration 43 \t| Loss = 11.057409 \t| Accuracy = 0.9230769\n",
      "Iteration 44 \t| Loss = 11.053912 \t| Accuracy = 0.9230769\n",
      "Iteration 45 \t| Loss = 11.050416 \t| Accuracy = 0.9230769\n",
      "Iteration 46 \t| Loss = 11.046922 \t| Accuracy = 0.9230769\n",
      "Iteration 47 \t| Loss = 11.043428 \t| Accuracy = 0.9230769\n",
      "Iteration 48 \t| Loss = 11.039936 \t| Accuracy = 0.9230769\n",
      "Iteration 49 \t| Loss = 11.036445 \t| Accuracy = 0.9230769\n",
      "Iteration 50 \t| Loss = 11.032953 \t| Accuracy = 0.9230769\n",
      "Iteration 51 \t| Loss = 11.029464 \t| Accuracy = 0.9230769\n",
      "Iteration 52 \t| Loss = 11.025974 \t| Accuracy = 0.9230769\n",
      "Iteration 53 \t| Loss = 11.022488 \t| Accuracy = 0.9230769\n",
      "Iteration 54 \t| Loss = 11.019 \t| Accuracy = 0.9230769\n",
      "Iteration 55 \t| Loss = 11.015516 \t| Accuracy = 0.9230769\n",
      "Iteration 56 \t| Loss = 11.012031 \t| Accuracy = 0.9230769\n",
      "Iteration 57 \t| Loss = 11.008547 \t| Accuracy = 0.9230769\n",
      "Iteration 58 \t| Loss = 11.005065 \t| Accuracy = 0.9230769\n",
      "Iteration 59 \t| Loss = 11.001585 \t| Accuracy = 0.9230769\n",
      "Iteration 60 \t| Loss = 10.998106 \t| Accuracy = 0.9230769\n",
      "Iteration 61 \t| Loss = 10.994627 \t| Accuracy = 0.9230769\n",
      "Iteration 62 \t| Loss = 10.991149 \t| Accuracy = 0.9230769\n",
      "Iteration 63 \t| Loss = 10.987671 \t| Accuracy = 0.9230769\n",
      "Iteration 64 \t| Loss = 10.984196 \t| Accuracy = 0.9230769\n",
      "Iteration 65 \t| Loss = 10.9807205 \t| Accuracy = 0.9230769\n",
      "Iteration 66 \t| Loss = 10.977247 \t| Accuracy = 0.9230769\n",
      "Iteration 67 \t| Loss = 10.973775 \t| Accuracy = 0.9230769\n",
      "Iteration 68 \t| Loss = 10.970303 \t| Accuracy = 0.9230769\n",
      "Iteration 69 \t| Loss = 10.966832 \t| Accuracy = 0.9230769\n",
      "Iteration 70 \t| Loss = 10.963362 \t| Accuracy = 0.9230769\n",
      "Iteration 71 \t| Loss = 10.959893 \t| Accuracy = 0.9230769\n",
      "Iteration 72 \t| Loss = 10.956427 \t| Accuracy = 0.9230769\n",
      "Iteration 73 \t| Loss = 10.95296 \t| Accuracy = 0.9230769\n",
      "Iteration 74 \t| Loss = 10.949493 \t| Accuracy = 0.9230769\n",
      "Iteration 75 \t| Loss = 10.946029 \t| Accuracy = 0.9230769\n",
      "Iteration 76 \t| Loss = 10.942566 \t| Accuracy = 0.9230769\n",
      "Iteration 77 \t| Loss = 10.939104 \t| Accuracy = 0.9230769\n",
      "Iteration 78 \t| Loss = 10.935642 \t| Accuracy = 0.9230769\n",
      "Iteration 79 \t| Loss = 10.932182 \t| Accuracy = 0.9230769\n",
      "Iteration 80 \t| Loss = 10.928722 \t| Accuracy = 0.9230769\n",
      "Iteration 81 \t| Loss = 10.925264 \t| Accuracy = 0.9230769\n",
      "Iteration 82 \t| Loss = 10.921807 \t| Accuracy = 0.9230769\n",
      "Iteration 83 \t| Loss = 10.918352 \t| Accuracy = 0.9230769\n",
      "Iteration 84 \t| Loss = 10.914896 \t| Accuracy = 0.9230769\n",
      "Iteration 85 \t| Loss = 10.911443 \t| Accuracy = 0.9230769\n",
      "Iteration 86 \t| Loss = 10.9079895 \t| Accuracy = 0.9230769\n",
      "Iteration 87 \t| Loss = 10.904537 \t| Accuracy = 0.9230769\n",
      "Iteration 88 \t| Loss = 10.901086 \t| Accuracy = 0.9230769\n",
      "Iteration 89 \t| Loss = 10.897635 \t| Accuracy = 0.9230769\n",
      "Iteration 90 \t| Loss = 10.894185 \t| Accuracy = 0.9230769\n",
      "Iteration 91 \t| Loss = 10.890736 \t| Accuracy = 0.9230769\n",
      "Iteration 92 \t| Loss = 10.887288 \t| Accuracy = 0.9230769\n",
      "Iteration 93 \t| Loss = 10.8838415 \t| Accuracy = 0.9230769\n",
      "Iteration 94 \t| Loss = 10.880397 \t| Accuracy = 0.9230769\n",
      "Iteration 95 \t| Loss = 10.876953 \t| Accuracy = 0.9230769\n",
      "Iteration 96 \t| Loss = 10.873508 \t| Accuracy = 0.9230769\n",
      "Iteration 97 \t| Loss = 10.870067 \t| Accuracy = 0.9230769\n",
      "Iteration 98 \t| Loss = 10.866625 \t| Accuracy = 0.9230769\n",
      "Iteration 99 \t| Loss = 10.863185 \t| Accuracy = 0.9230769\n",
      "\n",
      "Accuracy on test set: 0.88235295\n"
     ]
    }
   ],
   "source": [
    "#saver=tf.train.Saver() #SALVAR LA SECCION PARA PODERLA UTILIZAR LUEGO\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"Tensorboard\", sess.graph)\n",
    "    #print(sess)\n",
    "    sess.run(init)\n",
    "    #saver.save(sess, 'modelo')\n",
    "    for i in range(n_iterations):\n",
    "        sess.run(train_step, feed_dict={X: input_data.values, Y: output_data.values})\n",
    "        #if i % 10 == 0:\n",
    "        summary_results, loss, acc = sess.run([all_summary, cross_entropy, accuracy], feed_dict={X: input_data.values, Y: output_data.values})\n",
    "                #    writer.add_summary(summary_results, i)\n",
    "        print(\"Iteration\", str(i), \"\\t| Loss =\", str(loss), \"\\t| Accuracy =\", str(acc))\n",
    "    \n",
    "        if acc==1:\n",
    "            break\n",
    "    test_accuracy = sess.run(accuracy, feed_dict={X: input_data_test.values, Y: output_data_test.values})\n",
    "    print(\"\\nAccuracy on test set:\", test_accuracy)\n",
    "        \n",
    "    #saver.save(sess, 'modelo') #SALVAR EL MODELO EXTERNAMENTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBAR EL MODELO CON LA DATA DE MUESTRA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2aede903744e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'graph' is not defined"
     ]
    }
   ],
   "source": [
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
