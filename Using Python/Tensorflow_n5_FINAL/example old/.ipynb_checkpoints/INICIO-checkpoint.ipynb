{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**PAQUETERIAS NECESARIAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "x = [6,3,6,9,12,24]\n",
    "y = [3,5,78,12,23,56]\n",
    "# put 0s on the y-axis, and put the y axis on the z-axis\n",
    "surf = ax.plot(xs=x, ys=[0]*len(x), zs=y, zdir='z', label='ys=0, zdir=z')\n",
    "plt.show(surf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INCLUYE TODOS LOS PAQUETES A USAR\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow import keras\n",
    " # Bibliotecas de ayuda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.signal import gaussian\n",
    " # Biblioteca para datos de entrenamiento\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py as h # manipular extensiones\n",
    "# FUNCIONES DEFINIDAS PARA USO NECESARIO\n",
    "import timeit\n",
    "import PAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTRADA DE LA INFORMACION, ORDENAMIENTO DE LA INFORMACION A USAR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # ENTRAR LA INFORMACION DESDE UN ARCHIVO EXTERNO\n",
    "FILE  = h.File(\"DATOS/TODOS.h5\", 'r')\n",
    "INPUT = np.vstack([FILE[\"qcd/images\"][:], FILE[\"wprime/images\"][:]]); INPUT=INPUT/np.max(INPUT) # SE NORMALIZA\n",
    "LABEL = np.hstack([FILE[\"qcd/labels\"][:], FILE[\"wprime/labels\"][:]])\n",
    "OUTPUT_LINEAL = np.ones((len(LABEL), 2));\n",
    "OUTPUT_LINEAL[:,0] = LABEL < 1    ;     OUTPUT_LINEAL[:,1] = LABEL > 0\n",
    " # REACONDICIONAR LA INFORMACION INPUT EN UNA MATRIX PARA SU RAPIDO ACCESO\n",
    "INPUT_LINEAL = np.reshape(INPUT, [len(INPUT),-1]) # LA INFORMACION SE LINEALIZA Y SE LOCALIZA EN LAS FILAS\n",
    " # SEPARAR LA INFO PARA ENTRENAR DE LA QUE SERA USADA PARA EL TEST DE CORRESPONDENCIA\n",
    "INPUT_LINEAL, INPUT_LINEAL_TEST, OUTPUT_LINEAL, OUTPUT_LINEAL_TEST = train_test_split( \n",
    "    INPUT_LINEAL, OUTPUT_LINEAL, test_size=0.2, shuffle = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARAMETROS INICIALES DE ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLASE DE LOS VALORES A TENER EN CUENTA\n",
    "'''class arreglo():\n",
    "    def __init__( self , v_input ):#, exp = 1 , cross_entropy = 1, n_iterations = 3000, dropout = 0.5):\n",
    "        self.n_capas  = 2;         self.v_output = 2;         self.v_input = v_input \n",
    "        self.exp      = 1;\n",
    "        #self.matrix_neuronas = {}\n",
    "        self.learning_rate = 1e-1; self.cross_entropy = 1;    self.n_iterations  = 3000;\n",
    "        self.dropout       = 0.5;\n",
    "        self.n_step_visual_process = 10;'''\n",
    "## CLASE DE LOS VALORES A TENER EN CUENTA\n",
    "config = tf.compat.v1.placeholder(\"float\")\n",
    "config.v_input= len(INPUT_LINEAL[0,:]); config.v_output = len(OUTPUT_LINEAL[0,:]);#, exp = 1 , cross_entropy = 1, n_iterations = 3000, dropout = 0.5):\n",
    "config.n_capas  = 2;                    config.exp      = 1;\n",
    "#self.matrix_neuronas = {}\n",
    "config.learning_rate = 1e-1; config.cross_entropy = 1;    config.n_iterations  = 3000;\n",
    "config.dropout       = 0.5;\n",
    "config.n_step_visual_process = 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# def neuronas(v_input, v_output, n_capas , exp ):\n",
    "def neuronas(v_input, v_output, exp = 1, n_capas = 2, modo = 'poly' ):\n",
    "    x = np.ones(n_capas + 2)\n",
    "    if  exp >= 1: #modo == 'poly':\n",
    "        for i in range(n_capas + 2):\n",
    "            x[len(x)-i-1] = round(( v_input - v_output )*pow(i/(n_capas + 1 ), exp) + v_output)\n",
    "            #print(x[i])\n",
    "            #print(i)\n",
    "    elif exp < 1:\n",
    "        for i in range(n_capas + 2):\n",
    "            x[len(x)-i-1] = round(( v_input - v_output )*pow(i/(n_capas + 1 ), 1/exp) + v_output)\n",
    "            #print(x[i])\n",
    "            #print(i)\n",
    "    return x'''\n",
    "## DEFINICION DE LOS MODOS DE ELECCION DE CAPAS OCULTAS Y NUMEROS DE NEURONAS\n",
    "def neuronas( config ): #v_input, v_output, n_capas = 2, exp = 1,  modo = 'poly' ):\n",
    "    #config = Dd()\n",
    "    x = np.ones(config.n_capas + 2)\n",
    "    #print(x)\n",
    "    if  config.exp >= 1: #modo == 'poly':\n",
    "        for i in range(config.n_capas + 2):\n",
    "            x[len(x)-i-1] = round(( config.v_input - config.v_output )*pow(i/(config.n_capas + 1 ), config.exp) + config.v_output)\n",
    "            #print(x[i])\n",
    "            #print(i)\n",
    "    elif config.exp < 1:\n",
    "        for i in range(config.n_capas + 2):\n",
    "            x[len(x)-i-1] = round(( config.v_input - config.v_output )*pow(i/( config.n_capas + 1 ), -1/config.exp) + config.v_output)\n",
    "            #print(x[i])\n",
    "            #print(i)\n",
    "    config.matrix_neuronas = np.int64(x)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(neuronas(100,2,3))\n",
    "config = neuronas(config)\n",
    "n = config.matrix_neuronas\n",
    "#print(n)\n",
    "#config.n_iterations = 3000   ;   dropout = 0.5\n",
    " # print(range(len(n)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.compat.v1.placeholder(\"float\", [None, n[0]], name = \"Estructura_X\"); # Estructura de la entrada\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del Y\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del Y\n",
    "Y = tf.compat.v1.placeholder(\"float\", [None, n[len(n)-1]], name = \"Placeholder_y\") #Estructura de la salida\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(n)-1):\n",
    "    #print(n[i])\n",
    "    #print(i)\n",
    "    weights = tf.Variable(tf.truncated_normal([n[i], n[i+1]], stddev=0.1), name=f\"w{i}\")\n",
    "    biases = tf.Variable(tf.constant(0.1, shape=[n[i+1]]), name=f\"b{i}\")\n",
    "    if  i==0: # CONDICION INICIAL\n",
    "        \n",
    "        layer = tf.add(tf.matmul(X, weights), biases, name=f\"layer{i}\")\n",
    "    #elif i==len(n)-2: # CONDICION FINAL\n",
    "    #    print(tf.add(tf.matmul(layer, weights),biases))\n",
    "    #    layer = tf.matmul(layer, weights) + biases  \n",
    "    else: # VALORES INTERNMEDIOS\n",
    "        layer = tf.add(tf.matmul(layer, weights), biases, name=f\"layer{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=layer))\n",
    "train_step = tf.compat.v1.train.AdamOptimizer(config.learning_rate).minimize(cross_entropy)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(layer, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INICIALIZAR EL ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.compat.v1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_summary = tf.compat.v1.summary.scalar(\"Cost\", cross_entropy)\n",
    "acc_summary = tf.compat.v1.summary.scalar(\"Accuracy\", accuracy)\n",
    "all_summary = tf.compat.v1.summary.merge_all()#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saver=tf.train.Saver() #SALVAR LA SECCION PARA PODERLA UTILIZAR LUEGO\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"Tensorboard\", sess.graph)\n",
    "    #print(sess)\n",
    "    sess.run(init)\n",
    "    #saver.save(sess, 'modelo')\n",
    "    for i in range(config.n_iterations):\n",
    "        sess.run(train_step, feed_dict={X: INPUT_LINEAL, Y:OUTPUT_LINEAL}) # CORRIDA\n",
    "        \n",
    "        summary_results, loss, acc = sess.run([all_summary, cross_entropy, accuracy], feed_dict={X: INPUT_LINEAL, Y: OUTPUT_LINEAL})\n",
    "        writer.add_summary(summary_results, i)\n",
    "        if (i)%10 == 0:\n",
    "            print(\"Iteration\", str(i), \"\\t| Loss =\", str(loss), \"\\t| Accuracy =\", str(acc))\n",
    "    \n",
    "        if acc>.70:\n",
    "            print(\"Iteration\", str(i), \"\\t| Loss =\", str(loss), \"\\t| Accuracy =\", str(acc))\n",
    "            break\n",
    "    test_accuracy = sess.run(accuracy, feed_dict={X: INPUT_LINEAL_TEST, Y: OUTPUT_LINEAL_TEST})\n",
    "    print(\"\\nAccuracy on test set:\", test_accuracy)\n",
    "    \n",
    "    a, b = sess.run([tf.argmax(layer, 1),tf.argmax(Y,1)], feed_dict={X: INPUT_LINEAL, Y: OUTPUT_LINEAL}) \n",
    "    \n",
    "    for ea, eb in zip(a, b):\n",
    "        print(ea,eb)\n",
    "    #saver.save(sess, 'modelo') #SALVAR EL MODELO EXTERNAMENTE'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PAQUETERIAS NECESARIAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
