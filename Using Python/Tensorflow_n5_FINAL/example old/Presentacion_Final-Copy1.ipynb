{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**PAQUETERIAS NECESARIAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d8cf70b36849>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpickled_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pickled_file.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickled_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mwebsite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickled_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0menglish_french\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickled_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    " \n",
    "pickled_file = open('pickled_file.pickle', 'rb')\n",
    " \n",
    "name = pickle.load(pickled_file)\n",
    "website = pickle.load(pickled_file)\n",
    "english_french = pickle.load(pickled_file)\n",
    "tup = pickle.load(pickled_file)\n",
    " \n",
    "print('Name: ')\n",
    "print(name)\n",
    "print('Website:')\n",
    "print(website)\n",
    "print('Englsh to French:')\n",
    "print(english_french)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INCLUYE TODOS LOS PAQUETES A USAR\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow import keras\n",
    " # Bibliotecas de ayuda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.signal import gaussian\n",
    " # Biblioteca para datos de entrenamiento\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py as h # manipular extensiones\n",
    "# FUNCIONES DEFINIDAS PARA USO NECESARIO\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTRADA DE LA INFORMACION, ORDENAMIENTO DE LA INFORMACION A USAR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " # ENTRAR LA INFORMACION DESDE UN ARCHIVO EXTERNO\n",
    "FILE  = h.File(\"DATOS/TODOS.h5\", 'r')\n",
    "INPUT = np.vstack([FILE[\"qcd/images\"][:], FILE[\"wprime/images\"][:]]); INPUT=INPUT/np.max(INPUT) # SE NORMALIZA\n",
    "LABEL = np.hstack([FILE[\"qcd/labels\"][:], FILE[\"wprime/labels\"][:]])\n",
    "OUTPUT_LINEAL = np.ones((len(LABEL), 2));\n",
    "OUTPUT_LINEAL[:,0] = LABEL < 1    ;     OUTPUT_LINEAL[:,1] = LABEL > 0\n",
    " # REACONDICIONAR LA INFORMACION INPUT EN UNA MATRIX PARA SU RAPIDO ACCESO\n",
    "INPUT_LINEAL = np.reshape(INPUT, [len(INPUT),-1]) # LA INFORMACION SE LINEALIZA Y SE LOCALIZA EN LAS FILAS\n",
    " # SEPARAR LA INFO PARA ENTRENAR DE LA QUE SERA USADA PARA EL TEST DE CORRESPONDENCIA\n",
    "INPUT_LINEAL, INPUT_LINEAL_TEST, OUTPUT_LINEAL, OUTPUT_LINEAL_TEST = train_test_split( \n",
    "    INPUT_LINEAL, OUTPUT_LINEAL, test_size=0.2, shuffle = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCIONES INICIALES Y NECESARIAS PARA EL ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLASE DE LOS VALORES A TENER EN CUENTA\n",
    "'''class arreglo():\n",
    "    def __init__( self , v_input ):#, exp = 1 , cross_entropy = 1, n_iterations = 3000, dropout = 0.5):\n",
    "        self.n_capas  = 2;         self.v_output = 2;         self.v_input = v_input \n",
    "        self.exp      = 1;\n",
    "        #self.matrix_neuronas = {}\n",
    "        self.learning_rate = 1e-1; self.cross_entropy = 1;    self.n_iterations  = 3000;\n",
    "        self.dropout       = 0.5;\n",
    "        self.n_step_visual_process = 10;'''\n",
    "## CLASE DE LOS VALORES A TENER EN CUENTA\n",
    "config = tf.compat.v1.placeholder(\"float\")\n",
    "config.v_input= len(INPUT_LINEAL[0,:]); config.v_output = len(OUTPUT_LINEAL[0,:]);#, exp = 1 , cross_entropy = 1, n_iterations = 3000, dropout = 0.5):\n",
    "config.n_capas  = 2;                    config.exp      = 1;\n",
    "#self.matrix_neuronas = {} # SE RELLENARA EN EL FUTURO\n",
    "config.learning_rate = 1e-1; config.cross_entropy = 1;    config.n_iterations  = 3000;\n",
    "config.dropout       = 0.5;\n",
    "config.n_step_visual_process = 10;\n",
    "## NO DEBEN VOLVERSE A DEFINIR BAJO NINGUN CONCEPTO\n",
    "config.X = tf.compat.v1.placeholder(\"float\", shape = [None,len(INPUT_LINEAL[0,:])] ) #, name= \"input_size2\"); # Estructura de la entrada\n",
    "config.Y = tf.compat.v1.placeholder(\"float\", shape = [None,len(OUTPUT_LINEAL[0,:])] ) #, name= \"output_size2\") #Estructura de la salida\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINICION DE LOS MODOS DE ELECCION DE CAPAS OCULTAS Y NUMEROS DE NEURONAS\n",
    "def neuronas( config ): #v_input, v_output, n_capas = 2, exp = 1,  modo = 'poly' ):\n",
    "    #config = Dd()\n",
    "    x = np.ones(config.n_capas + 2)\n",
    "    #print(x)\n",
    "    if  config.exp >= 1: #modo == 'poly':\n",
    "        for i in range(config.n_capas + 2):\n",
    "            x[len(x)-i-1] = round(( config.v_input - config.v_output )*pow(i/(config.n_capas + 1 ), config.exp) + config.v_output)\n",
    "            #print(x[i])\n",
    "            #print(i)\n",
    "    elif config.exp < 1:\n",
    "        for i in range(config.n_capas + 2):\n",
    "            x[len(x)-i-1] = round(( config.v_input - config.v_output )*pow(i/( config.n_capas + 1 ), -1/config.exp) + config.v_output)\n",
    "            #print(x[i])\n",
    "            #print(i)\n",
    "    config.matrix_neuronas = np.int64(x)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = neuronas( config ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(config.cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ORGANIZACION DE LA ESTRUCTURA INTERNA DE ENTRENAMIENTO ##\n",
    "def inicio( INPUT_LINEAL, INPUT_LINEAL_TEST, OUTPUT_LINEAL , OUTPUT_LINEAL_TEST , config):\n",
    "    config = neuronas( config )\n",
    "    #proceso iteractivo dinamico \n",
    "    for i in range(len(config.matrix_neuronas)-1):\n",
    "\n",
    "        weights = tf.Variable( tf.truncated_normal([config.matrix_neuronas[i], config.matrix_neuronas[i+1]], stddev=0.1) , \n",
    "                              name = f\"weights-w{i}\")\n",
    "        biases = tf.Variable(tf.constant(0.1, shape=[config.matrix_neuronas[i+1]]) , name=f\"biases_b{i}\" )\n",
    "        \n",
    "        if  i == 0: # CONDICION INICIAL\n",
    "            layer = tf.add(tf.matmul( config.X, weights), biases , name=f\"layer_l{i}\" )\n",
    "        else: # VALORES INTERNMEDIOS\n",
    "            layer = tf.add(tf.matmul(    layer, weights), biases , name=f\"layer_l{i}\" )\n",
    "    # PARAMETROS FINALES PARA CARACTERIZACION \n",
    "    config.cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = config.Y, logits=layer) , \n",
    "                                          name= \"Definition_of_cross_entropy\")\n",
    "    config.train_step    = tf.compat.v1.train.AdamOptimizer( config.learning_rate ).minimize( config.cross_entropy , \n",
    "                                          name= \"Definition_of_train_step\")\n",
    "    config.correct_pred  = tf.equal(tf.argmax(layer, 1), tf.argmax( config.Y , 1) , \n",
    "                                          name= \"Definition_of_correct_pred\")\n",
    "    config.accuracy      = tf.reduce_mean(tf.cast( config.correct_pred  , tf.float32) ,\n",
    "                                          name= \"Definition_of_accuracy\")\n",
    "#    return config\n",
    "#def inicio( INPUT_LINEAL, INPUT_LINEAL_TEST, OUTPUT_LINEAL , OUTPUT_LINEAL_TEST , config):\n",
    "    \n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "    config.cost_summary = tf.compat.v1.summary.scalar(\"Cost\", config.cross_entropy)\n",
    "    config.acc_summary = tf.compat.v1.summary.scalar(\"Accuracy\", config.accuracy)\n",
    "    config.all_summary = tf.compat.v1.summary.merge_all()#'''\n",
    "    \n",
    "    \n",
    "    #saver=tf.train.Saver() #SALVAR LA SECCION PARA PODERLA UTILIZAR LUEGO\n",
    "    with tf.Session() as sess:\n",
    "        writer = tf.summary.FileWriter(\"Tensorboard\", sess.graph)\n",
    "        #print(sess)\n",
    "        sess.run(init)\n",
    "        #saver.save(sess, 'modelo')\n",
    "        toc_general = 0  \n",
    "        for i in range(config.n_iterations):\n",
    "            tic = timeit.default_timer()\n",
    "            sess.run(config.train_step, feed_dict={ config.X: INPUT_LINEAL, config.Y:OUTPUT_LINEAL}) # CORRIDA\n",
    "\n",
    "            config.summary_results, config.loss, config.acc = sess.run([config.all_summary, config.cross_entropy, config.accuracy], \n",
    "                                                  feed_dict={config.X: INPUT_LINEAL, config.Y: OUTPUT_LINEAL})\n",
    "            writer.add_summary(config.summary_results, i)\n",
    "            \n",
    "            toc = timeit.default_timer() ;   toc_general += toc ;\n",
    "            if (i)%10 == 0:\n",
    "                print(\"Iteration\", str(i), \"\\t| Loss =\", str( config.loss ), \"\\t| Accuracy =\", str( config.acc )\n",
    "                     , \"\\t| Time =\", str( toc - tic ))\n",
    "            \n",
    "            if config.acc>.9:\n",
    "                print(\"Iteration\", str(i), \"\\t| Loss =\", str( config.loss ), \"\\t| Accuracy =\", str( config.acc ))\n",
    "                break\n",
    "        config.test_accuracy = sess.run(config.accuracy, feed_dict={config.X: INPUT_LINEAL_TEST, config.Y: OUTPUT_LINEAL_TEST})\n",
    "        print(\"\\n Accuracy on test set:\", config.test_accuracy , \"\\n Mean time of Iterations:\", str(toc_general/i) )\n",
    "\n",
    "        #a, b = sess.run([tf.argmax(layer, 1),tf.argmax(Y,1)], feed_dict={X: INPUT_LINEAL, Y: OUTPUT_LINEAL}) \n",
    "\n",
    "        #for ea, eb in zip(a, b):\n",
    "        #    print(ea,eb)\n",
    "    #return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INICIALIZAR EL ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 \t| Loss = 42.924084 \t| Accuracy = 0.5969325 \t| Time = 0.6084820999999998\n",
      "Iteration 10 \t| Loss = 2.690886 \t| Accuracy = 0.26617128 \t| Time = 0.2924161999999999\n",
      "Iteration 20 \t| Loss = 11.881383 \t| Accuracy = 0.46403736 \t| Time = 0.26037900000000036\n",
      "Iteration 30 \t| Loss = 6.6181126 \t| Accuracy = 0.48690102 \t| Time = 0.2839989000000003\n",
      "Iteration 40 \t| Loss = 1.4642833 \t| Accuracy = 0.877203 \t| Time = 0.31932079999999985\n",
      "Iteration 50 \t| Loss = 3.6809416 \t| Accuracy = 0.83814424 \t| Time = 0.30093670000000117\n",
      "Iteration 60 \t| Loss = 1.3226497 \t| Accuracy = 0.88425267 \t| Time = 0.2697593000000005\n",
      "Iteration 64 \t| Loss = 0.44879648 \t| Accuracy = 0.901972\n",
      "\n",
      " Accuracy on test set: 0.89485717 \n",
      " Mean time of Iterations: 21.406706671875\n"
     ]
    }
   ],
   "source": [
    "#config = neuronas( config )\n",
    "inicio( INPUT_LINEAL, INPUT_LINEAL_TEST, OUTPUT_LINEAL , OUTPUT_LINEAL_TEST , config )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 \t| Loss = 42.593365 \t| Accuracy = 0.5969325\n",
      "Iteration 7 \t| Loss = 1.9583709 \t| Accuracy = 0.839859\n",
      "\n",
      "Accuracy on test set: 0.8445714\n"
     ]
    }
   ],
   "source": [
    "'''#proceso iteractivo dinamico \n",
    "for i in range(len(config.matrix_neuronas)-1):\n",
    "    weights = tf.Variable( tf.truncated_normal([config.matrix_neuronas[i], config.matrix_neuronas[i+1]], stddev=0.1) \n",
    "                            , name = f\"weights-w{i}\")\n",
    "    biases = tf.Variable(tf.constant(0.1, shape=[config.matrix_neuronas[i+1]]) \n",
    "                            , name=f\"biases_b{i}\" )\n",
    "    \n",
    "    if  i == 0: # CONDICION INICIAL\n",
    "        layer = tf.add(tf.matmul(config.X, weights), biases , name=f\"layer_l{i}\" )\n",
    "    else: # VALORES INTERNMEDIOS\n",
    "        layer = tf.add(tf.matmul(layer   , weights), biases , name=f\"layer_l{i}\" )\n",
    "    \n",
    "# PARAMETROS FINALES PARA CARACTERIZACION \n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = config.Y, logits=layer) )\n",
    "train_step    = tf.compat.v1.train.AdamOptimizer( config.learning_rate ).minimize( cross_entropy )\n",
    "correct_pred  = tf.equal(tf.argmax(layer, 1), tf.argmax( config.Y , 1) )\n",
    "accuracy      = tf.reduce_mean(tf.cast( correct_pred  , tf.float32))#,\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "cost_summary = tf.compat.v1.summary.scalar(\"Cost\", config.cross_entropy)\n",
    "acc_summary = tf.compat.v1.summary.scalar(\"Accuracy\", accuracy)\n",
    "all_summary = tf.compat.v1.summary.merge_all()#\n",
    "\n",
    "#saver=tf.train.Saver() #SALVAR LA SECCION PARA PODERLA UTILIZAR LUEGO\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"Tensorboard\", sess.graph)\n",
    "    sess.run(init)\n",
    "    for i in range(config.n_iterations):\n",
    "        sess.run( train_step, feed_dict={config.X: INPUT_LINEAL, config.Y:OUTPUT_LINEAL})  # CORRIDA\n",
    "        #summary_results, loss, acc = sess.run( [all_summary, config.cross_entropy, accuracy], \n",
    "        #                                       feed_dict={X: INPUT_LINEAL, Y: OUTPUT_LINEAL} )\n",
    "        summary_results, loss, acc = sess.run([all_summary, cross_entropy, accuracy], \n",
    "                                              feed_dict={config.X: INPUT_LINEAL, config.Y: OUTPUT_LINEAL})\n",
    "        writer.add_summary(summary_results, i)\n",
    "        if (i)%10 == 0:\n",
    "            print(\"Iteration\", str(i), \"\\t| Loss =\", str(loss), \"\\t| Accuracy =\", str(acc))\n",
    "\n",
    "        if acc>.70:\n",
    "            print(\"Iteration\", str(i), \"\\t| Loss =\", str(loss), \"\\t| Accuracy =\", str(acc))\n",
    "            break\n",
    "    test_accuracy = sess.run(accuracy, feed_dict={config.X: INPUT_LINEAL_TEST, config.Y: OUTPUT_LINEAL_TEST})\n",
    "    print(\"\\nAccuracy on test set:\", test_accuracy)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PAQUETERIAS NECESARIAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 \t| Loss = 15.195285 \t| Accuracy = 0.5969325 \t| Time = 0.7342865999999972\n",
      "Iteration 10 \t| Loss = 15.678536 \t| Accuracy = 0.7360198 \t| Time = 0.49411649999999696\n",
      "Iteration 20 \t| Loss = 10.265811 \t| Accuracy = 0.450986 \t| Time = 0.42484879999999947\n",
      "Iteration 30 \t| Loss = 5.3215785 \t| Accuracy = 0.7708869 \t| Time = 0.41935369999999494\n",
      "Iteration 40 \t| Loss = 2.76392 \t| Accuracy = 0.85681623 \t| Time = 0.5196905000000029\n",
      "Iteration 49 \t| Loss = 0.6513335 \t| Accuracy = 0.90806895\n",
      "\n",
      " Accuracy on test set: 0.9047619 \n",
      " Mean time of Iterations: 50.20468473877552\n"
     ]
    }
   ],
   "source": [
    "inicio( INPUT_LINEAL, INPUT_LINEAL_TEST, OUTPUT_LINEAL , OUTPUT_LINEAL_TEST , config )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "625\n",
      "0.1\n",
      "Tensor(\"Definition_of_cross_entropy_1:0\", shape=(), dtype=float32)\n",
      "3000\n",
      "0.5\n",
      "10\n",
      "625\n",
      "625\n",
      "2\n",
      "(10497, 625)\n",
      "(10497, 2)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d5288bae3294>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mINPUT_LINEAL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mOUTPUT_LINEAL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "print(config.matrix_neuronas[-1] )\n",
    "print( config.n_capas )\n",
    "print( config.v_output )\n",
    "print( config.v_input )\n",
    "print( config.learning_rate )\n",
    "print( config.cross_entropy )\n",
    "print( config.n_iterations )     \n",
    "print( config.dropout )\n",
    "print( config.n_step_visual_process )\n",
    "print( config.v_input )\n",
    "print( len(INPUT_LINEAL[0,:]) )\n",
    "print( len(OUTPUT_LINEAL[0,:]) )\n",
    "print( INPUT_LINEAL.shape )\n",
    "print( OUTPUT_LINEAL.shape )\n",
    "print( X.shape )\n",
    "print( Y.shape )\n",
    "print( config.train_step )\n",
    "print( config.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def inicio( INPUT_LINEAL, INPUT_LINEAL_TEST, OUTPUT_LINEAL , OUTPUT_LINEAL_TEST , CONFIG):   \n",
    "    cost_summary  = tf.compat.v1.summary.scalar(\"Cost\", config.cross_entropy)\n",
    "    acc_summary   = tf.compat.v1.summary.scalar(\"Accuracy\", config.accuracy)\n",
    "    all_summary   = tf.compat.v1.summary.merge_all()\n",
    "    # COMENZAR EL PROCESO DE ENTRENAMIENTO\n",
    "    X = tf.compat.v1.placeholder(\"float\", shape = [None,len(INPUT_LINEAL[0,:])] , name= \"input_size\"); # Estructura de la entrada\n",
    "    Y = tf.compat.v1.placeholder(\"float\", shape = [None,len(OUTPUT_LINEAL[0,:])] , name= \"output_size\") #Estructura de la salida\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        writer = tf.summary.FileWriter(\"Tensorboard\", sess.graph)\n",
    "        sess.run(init)\n",
    "        #toc_general=0; # TIEMPO DE TODO EL PROCESO ITERATIVO\n",
    "        for i in range(CONFIG.n_iterations):\n",
    "            #tic = 1#timeit.default_timer(); # COMENZAR EL CONTEO DEL TIEMPO DEL PROCESO\n",
    "            sess.run(CONFIG.train_step, feed_dict={X:INPUT_LINEAL , Y:OUTPUT_LINEAL}) # CORRIDA\n",
    "\n",
    "            summary_results, loss, acc = sess.run([all_summary,  CONFIG.cross_entropy, CONFIG.accuracy], \n",
    "            #                                                           feed_dict = {X: INPUT_LINEAL, Y: OUTPUT_LINEAL} )\n",
    "            writer.add_summary(summary_results, i)\n",
    "            #toc = 2#timeit.default_timer(); # CORTE FINAL DEL TIEMPO PARA IMPRESION\n",
    "            if  (i)%100 == 0:\n",
    "                print(\"Iteration\", str(i), \"\\t| Loss =\", str(loss), \"\\t| Accuracy =\", str(acc))\n",
    "    \n",
    "            if  acc>.70:\n",
    "                print(\"Iteration\", str(i), \"\\t| Loss =\", str(loss), \"\\t| Accuracy =\", str(acc))\n",
    "                break\n",
    "            #toc_general += tic-toc;        \n",
    "        CONFIG.test_accuracy = sess.run(CONFIG.accuracy, feed_dict={X: INPUT_LINEAL_TEST, Y: OUTPUT_LINEAL_TEST})\n",
    "        print(\"\\nAccuracy on test set:\", CONFIG.test_accuracy)\n",
    "    \n",
    "    return CONFIG'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE REALIZA LA OPERACION UNA SOLA VEZ\n",
    "#print(len(INPUT_LINEAL[0,:]))\n",
    "#config = arreglo( v_input = len(INPUT_LINEAL[0,:]) )\n",
    "\n",
    "#config = neuronas( config )\n",
    "print(config.matrix_neuronas)\n",
    "#print(config.matrix_neuronas)\n",
    "#config = estructura( INPUT_LINEAL, OUTPUT_LINEAL , config )\n",
    "#X = tf.compat.v1.placeholder(\"float\", shape=[ None, len(INPUT_LINEAL[0,:]) ] , name= \"input_size00\"); # Estructura de la entrada\n",
    "#Y = tf.compat.v1.placeholder(\"float\", shape=[None, len(OUTPUT_LINEAL[0,:]) ] , name= \"output_size00\") #Estructura de la salida\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
