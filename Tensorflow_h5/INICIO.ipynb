{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**PAQUETERIAS NECESARIAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow import keras\n",
    "# Bibliotecas de ayuda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.signal import gaussian\n",
    "#Biblioteca para datos de entrenamiento\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py as h # manipular extensiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTRADA DE LA INFORMACION, ORDENAMIENTO DE LA INFORMACION A USAR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'signal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fa96c13d5e89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#print(convoluplot(INPUT[:,:,1], kernel))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#print(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINPUT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;31m## REACONDICIONAR LA INFORMACION EN UNA MATRIX PARA SU RAPIDO ACCESO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mINPUT_LINEAL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINPUT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINPUT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# LA INFORMACION SE LINEALIZA Y SE LOCALIZA EN LAS FILAS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'signal' is not defined"
     ]
    }
   ],
   "source": [
    "## ENTRAR LA INFORMACION DESDE UN ARCHIVO EXTERNO\n",
    "FILE = h.File(\"DATOS/new.h5\", 'r')\n",
    "INPUT  = np.vstack([FILE[\"tt/images\"][:], FILE[\"wprime/images\"][:]])\n",
    "LABEL = np.hstack([FILE[\"tt/labels\"][:], FILE[\"wprime/labels\"][:]])\n",
    "OUTPUT_LINEAL=np.ones((len(LABEL), 2));\n",
    "OUTPUT_LINEAL[:,0]=LABEL<1\n",
    "OUTPUT_LINEAL[:,1]=LABEL>0\n",
    "## CONVOLUCION\n",
    "def convoluplot(signal, kernel):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True)\n",
    "    ax1.plot(signal)\n",
    "    ax1.set_title('Signal')\n",
    "    ax2.plot(kernel)\n",
    "    ax2.set_title('Filter')\n",
    "    filtered = np.convolve(signal, kernel, \"same\") / sum(kernel)\n",
    "    ax3.plot(filtered)\n",
    "    ax3.set_title(\"Convolution\")\n",
    "    fig.show()\n",
    " \n",
    "kernel = gaussian(100, 10)\n",
    "#print(convoluplot(INPUT[:,:,1], kernel))\n",
    "#print(\n",
    "np.convolve(INPUT[:,:,1], signal, 'same')\n",
    "## REACONDICIONAR LA INFORMACION EN UNA MATRIX PARA SU RAPIDO ACCESO\n",
    "INPUT_LINEAL = np.reshape(INPUT, [len(INPUT),-1]) # LA INFORMACION SE LINEALIZA Y SE LOCALIZA EN LAS FILAS\n",
    "#OUTPUT_LINEAL = np.reshape(OUTPUT, [len(INPUT),-1])\n",
    "# SEPARAR LA INFO PARA ENTRENAR DE LA QUE SERA USADA PARA EL TEST DE CORRESPONDENCIA\n",
    "INPUT_LINEAL, INPUT_LINEAL_TEST, OUTPUT_LINEAL, OUTPUT_LINEAL_TEST = train_test_split( \n",
    "    INPUT_LINEAL, OUTPUT_LINEAL, test_size=0.2, shuffle = True);\n",
    "#print([[OUTPUT_LINEAL>1;OUTPUT_LINEAL>1]])\n",
    "print(len(INPUT_LINEAL[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.convolve([1,2,3],[0,1,0.5], 'same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARAMETROS INICIALES DE ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = np.int64(len(INPUT_LINEAL[0,:]))   # input layer\n",
    "n_hidden = np.round(np.int64(len(INPUT_LINEAL[0,:])/2))#np.int64(np.round(np.sqrt(len(label_user)))) # 1st hidden layer\n",
    "#n_hidden2 = 256 # 2nd hidden layer\n",
    "n_output = np.int64(2)   # output \n",
    "\n",
    "learning_rate = 1e-4;   n_iterations = 1000   ;   batch_size = 3;         dropout = 0.5\n",
    "\n",
    "X = tf.compat.v1.placeholder(\"float\", [None, n_input]); Y = tf.compat.v1.placeholder(\"float\", [None, n_output])\n",
    "\n",
    "weights = {'w1': tf.Variable(tf.random.normal([n_input, n_hidden])),\n",
    "    'out': tf.Variable(tf.random.normal([n_hidden, n_output]))}\n",
    "\n",
    "biases = {'b1': tf.Variable(tf.constant(0.1, shape=[n_hidden])),\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[n_output]))}\n",
    "\n",
    "layer_1 = tf.add(tf.matmul(X, weights['w1']), biases['b1'])\n",
    "output_layer = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=output_layer))\n",
    "train_step = tf.compat.v1.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(output_layer, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INICIALIZAR EL ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "cost_summary = tf.compat.v1.summary.scalar(\"Cost\", cross_entropy)\n",
    "acc_summary = tf.compat.v1.summary.scalar(\"Accuracy\", accuracy)\n",
    "all_summary = tf.compat.v1.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTRENAMIENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saver=tf.train.Saver() #SALVAR LA SECCION PARA PODERLA UTILIZAR LUEGO\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"Tensorboard\", sess.graph)\n",
    "    #print(sess)\n",
    "    sess.run(init)\n",
    "    #saver.save(sess, 'modelo')\n",
    "    for i in range(n_iterations):\n",
    "        sess.run(train_step, feed_dict={X: INPUT_LINEAL, Y:OUTPUT_LINEAL})\n",
    "        \n",
    "        summary_results, loss, acc = sess.run([all_summary, cross_entropy, accuracy], feed_dict={X: INPUT_LINEAL, Y: OUTPUT_LINEAL})\n",
    "        writer.add_summary(summary_results, i)\n",
    "        if i%200 == 0:\n",
    "            print(\"Iteration\", str(i), \"\\t| Loss =\", str(loss), \"\\t| Accuracy =\", str(acc))\n",
    "    \n",
    "        if acc==1:\n",
    "            break\n",
    "    test_accuracy = sess.run(accuracy, feed_dict={X: INPUT_LINEAL_TEST, Y: OUTPUT_LINEAL_TEST})\n",
    "    print(\"\\nAccuracy on test set:\", test_accuracy)\n",
    "    \n",
    "    a, b = sess.run([tf.argmax(output_layer, 1),tf.argmax(Y,1)], feed_dict={X: INPUT_LINEAL, Y: OUTPUT_LINEAL}) \n",
    "    \n",
    "    for ea, eb in zip(a, b):\n",
    "        print(ea,eb)\n",
    "    #saver.save(sess, 'modelo') #SALVAR EL MODELO EXTERNAMENTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PAQUETERIAS NECESARIAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
